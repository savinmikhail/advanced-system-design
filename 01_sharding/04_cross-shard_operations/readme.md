# Блок 2.4. Cross-Shard операции и оптимизации

## 2.4.0. Вступление

Мы научились шардировать данные, выбирать shard key, бороться с hot keys и даже динамически перестраивать layout шардинга так, 
чтобы кластер не умирал при росте нагрузки.

Но как бы мы не порезали данные, все равно придется столкнуться с операциями затрагивающими данные с нескольких а то и со всех шардов одновременно

Это называется **cross-shard операции**.

Примеры таких операций
* Cross-shard JOIN — страница заказа, где на одном экране нужны данные заказа, товара и продавца.
* Cross-shard Aggregation — отчёт “оборот по продавцам за неделю”, когда `orders` уже разрезаны по `userId` или регионам.
* Cross-shard Filtering / Search — поиск товара по атрибутам (цвет, размер, бренд, цена), размазанным по шардированным индексам.
* Cross-shard Transactions — списать деньги у покупателя, зачислить продавцу, применить комиссию и кешбек.
* Cross-shard Ordering / Pagination — глобальный “топ‑продажи” или “последние заказы по всей платформе”.
* Scatter-Gather Queries — любой глобальный поиск/отчёт, который не привязан к одному shard key.

## 2.4.3. Практические стратегии оптимизации

### 2.4.3.1. Data Locality — правильный shard key

Заметная часть cross-shard операций возникает из-за того, что шардирование сделали не по домену.

Правильный подход:

* маркетплейс — по `sellerId`:

    * все заказы и товары продавца локализованы.
* мессенджер — по `chatId`:

    * сообщения одного чата не размазываем по кластеру.

Если ключ выбран правильно:

* большая часть запросов **локальны**;
* JOIN происходит “внутри шарда”, а не через сеть;
* cross-shard остаются только там, где это **реально глобальная логика**.

### 2.4.3.2. Денормализация — убрать JOIN

Представим такую задачу:
страница “Мой заказ” должна показать список позиций, названия товаров, аватарку продавца и итоговую сумму 

В монолите мы следуем правилу:

> “Нормализация — это хорошо, 3НФ, чтобы не дублировать данные”.

В распределённой системе цена JOIN часто другая:

`JOIN` = сетевая cross-shard операция

Чтобы этого избежать, мы **дублируем** критичные поля в “место, где реально нужен ответ”.

Примеры в том же маркетплейсе:

* `username` в таблице `orders`:

    * чтобы страница заказов не ходила отдельно в `users` за именем покупателя.
* `price` в `order_items`:

    * чтобы считать сумму по позиции без похода в `products`.
* `sellerName` и рейтинг в `product_listing`:

    * чтобы отдавать карточку товара без отдельного JOIN с таблицей продавцов.

Плюсы:

* запросы становятся **локальными**;
* меньше cross-shard JOIN;
* latency уменьшается.

Минусы:

* **eventual consistency**:
  аватар сменили, а в заказе старый, пока не доедет событие;
* нужен pipeline событий / CDC / worker’ы, которые всё это пересчитывают.

> Нормализация это хорошо.
> Но масштабируемость и latency — еще лучше.

### 2.4.3.3. Scatter-Gather (Fan-Out) (разбросать собрать)

Если же запрос реально глобальный, например глобальный топ товаров, отчёт по всем продавцам

То делаем классический scatter-gather / fan-out:

1. Координатор получает запрос.
2. Рассылает его **на все (или на часть) шардов**.
3. Каждый шард считает **частичный результат**:

    * свою сумму, свой `COUNT`, свой топ-10.
4. Координатор собирает всё, мержит и отдаёт клиенту.

Но это приводит нас к новой проблеме

> Один медленный шард делает медленным **весь запрос**.
> Tail latency растёт примерно пропорционально количеству шардов.

Что можно с этим сделать?:

* **shard filtering** — ходить не на все шарды, а только на те, где точно есть кандидаты, благодаря подходу routing index, чуть позже его разберем
* кешировать partial-результаты на шардах;
* кешировать итоговый merge для популярных запросов;
* good enough/ early termination - при поиске топ-10 можно остановиться, когда уже набрали достаточно кандидатов и “хвост” мало что изменит

Fan-out не плох сам по себе
Плохо когда fan-out идет на все шарды всегда

### 2.4.3.4. Routing Index

В маркетплейсе пользователи фильтруют каталог по цене, бренду, цвету, размеру.
Ни один из этих атрибутов не совпадает с shard key, поэтому по умолчанию приходится делать fan-out на все шарды — дорого и увеличивает tail latency.

Routing index — это дополнительный слой, который отвечает на вопрос:

> “Какие шарды вообще имеет смысл трогать для такого фильтра?”

Важно не путать:

* **shard-map** — когда по shard key выбираем один шард.
* **routing index** — когда по фильтрам выбираем набор шардов-кандидатов.

Routing index — это **надстройка**, а не отдельное шардирование.

### Простой вариант: грубая статистика по шардям

Храним, например, диапазоны возрастов, которые есть на каждом шарде:

```text
Shard1 → [18–25], [40–60]
Shard2 → [30–40]
Shard3 → [18–25], [25–30]
```

Запрос `age=18–25` → дёргаем только `Shard1` и `Shard3`.

Это не точный индекс — просто фильтр, который отсеивает заведомо пустые шарды и снижает fan-out.

### Более точный вариант: глобальный secondary index

Отдельная таблица/сервис держит мапу:

```text
(age bucket, premium flag) → список user_id по шартам
```

По запросу `age=18–25&premium=true` роутер:

1. идёт в индекс;
2. получает список шардов и нужных ключей;
3. делает точечные запросы на эти шарды.

### Что это даёт

* fan-out уменьшается: вместо 64 шардов — 2–5;
* ниже tail latency;
* нагрузка распределяется предсказуемее.

### Цена

* индекс нужно обновлять при изменениях данных;
* это отдельная инфраструктура (хранение, репликация, мониторинг);
* возможен **лаг** между базой и индексом (как и в любой eventual consistent конструкции).

### 2.4.3.5. Cross-Shard Transactions: 2PC vs Saga

Подробнее о работе распределенных транзакций поговорим в следующей главе

## 2.4.3.6. Pre-Aggregation (MapReduce-стиль)

Если глобальные агрегаты неизбежны, самый быстрый запрос — тот, который уже посчитан.

Идея:

> Вместо того чтобы каждый раз бегать по всем шардам,
> мы считаем **частичные агрегаты на самих шардах**,
> а глобальный слой только их склеивает.

**Как выглядит в реальных системах:**

1. **Каждый шард ведёт свои локальные агрегаты**
   (по часам, дням, продавцам, товарам — в зависимости от модели).
   Они обновляются:

    * либо на write-path (`INSERT … ON CONFLICT DO UPDATE`),
    * либо периодическими джобами,
    * либо через событийный поток.

2. **Глобальный слой (API/отчёты)** просто читает локальные результаты
   и делает `SUM/COUNT/MIN/MAX` поверх них.

То есть вместо запроса:

```
SELECT SUM(amount) FROM orders   -- по всем шартам
```

мы выполняем:

```
SELECT SUM(amount_local) FROM aggregated_per_shard;
```

**Что это даёт:**

* снимает тяжёлые scatter-gather запросы с продового пути;
* стабилизирует tail latency;
* легко кешируется — данные изменяются батчами

**Цена:**

* данные слегка отстают от реального времени (секунды–минуты);
* нужен pipeline для поддержки агрегатов.

Но для большинства бизнес-метрик (оборот, просмотры, лайки, рейтинги, топ-товары) *“агрегаты, обновляемые раз в минуту”* — полностью достаточны.

## 2.4.3.7. Кэширование cross-shard запросов (сокращённая версия)

Кеш — это дешёвый способ уменьшить стоимость глобальных запросов (топы, отчётность), особенно если они меняются медленно

### Подходы

1. **Кеширование частичных результатов на шардах**
   Каждый шард хранит свои локальные агрегаты или “топы”, а merge-узел только склеивает их.
   Это резко снижает нагрузку на шарды при fan-out и уменьшает tail latency.

2. **Кеширование итогового результата на API-слое**
   Например, топ-100 товаров в категории.
   Обновлять такие данные раз в 60 секунд нормально для 99% пользовательских сценариев.

3. **Materialized views / precomputed buckets**
   Агрегаты, обновляемые батчами, тоже являются по сути слоем кеша — только в базе.

### Эффект

* в момент запросе не надо считать по всем шардам - только склеивать посчитанное
* tail latency уменьшается;
* нагрузка на шарды уменьшается/размазывается во времени

### Цена

* данные слегка отстают от реального времени → эстетическая проблема, но не функциональная;
* нужен минимальный пайплайн обновления кешей.

## 5. Hot keys

Так же тут еще раз всплывает проблема горячих шардов немного с другой стороны - любой cross-shard, зависящий от горячего шарда, начнёт тормозить или падать.

## 6. Закрытие и мостик к следующей теме (30 секунд)

Собираем всё в одну картинку:

* Cross-shard операции — **не баг**, а нормальная цена масштабируемости.
* Задача инженера — **минимизировать их количество и стоимость**:

    * правильным shard key,
    * денормализацией,
    * routing-индексами,
    * pre-aggregation,
    * кешированием,
    * управлением горячими шардами,
