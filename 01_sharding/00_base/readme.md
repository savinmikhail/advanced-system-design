### 2.0. Базовый ликбез: шардирование и партиционирование

#### 2.0.1. От какой боли вообще стартуем

Типичная картина:

* есть одна большая таблица `events` / `orders` / `logs`;
* она растёт годами;
* в ней уже десятки/сотни миллионов строк;
* индексы раздулись, VACUUM жрёт время, бэкапы занимают ночь;

Плюс операционные штуки:

* таблица приближается к физическим ограничениям:

    * диск под ней забит;
    * на одной файловой системе жить уже стремно;
* хотим:

    * “горячие” данные держать на SSD;
    * “холодные” архивы — на дешёвом HDD/облаке;
* иногда просто: “на одном сервере уже страшно держать такую тушу, которая в любой момент может занять терабайты”.

На этом фоне появляются два базовых инструмента:

* **партиционирование** — разрезать таблицу на части внутри одного инстанса БД;
* **шардирование** — разнести эти части по разным машинам/кластерам.

И тут важное честное предупреждение:

> **Шардирование — тяжёлая артиллерия.
> К нему идут, когда остальные варианты уже упёрлись в стену.**

Пока можно, делаем по порядку:

1. Нормализуем схему, чиним индексы, переписываем самые тупые запросы.
2. Выжимаем **вертикальное масштабирование** (CPU, RAM, диск, быстрые SSD).
3. Вводим **партиционирование** на одном кластере.
4. И только когда всё это уже не спасает по объёму/нагрузке —
   **лезем в шардирование**, с пониманием, что оно привезёт с собой кросс-шардовые транзакции, миграции и прочую боль.

---

#### 2.0.2. Вертикальное и горизонтальное разрезание

Есть два базовых направления, в которых можно резать данные.

##### 1) Вертикальное разрезание (vertical partitioning)

Делим таблицу **по столбцам**.

Примеры:

* выносим жирные, редко используемые поля (JSON-поля, большие текстовые комментарии, blob’ы) в отдельную таблицу;
* разделяем сущность на “ядро” и “обвес”:

    * `users_core(id, email, password_hash, state)`
    * `users_profile(user_id, name, avatar_url, bio, …)`

Зачем:

* уменьшить “ширину” критичного индекса;
* ускорить типичные SELECT’ы, которые не тащат гигабайты профилей;
* развести по разным подсистемам (core-данные и второстепенные).

Это **не совсем про распределённые системы**, но важно:

> Очень часто разговор “давайте шардировать” начинается там,
> где люди даже вертикально таблицу не разрезали и тащат всё в один монструозный SELECT.

##### 2) Горизонтальное разрезание (horizontal partitioning)

Делим таблицу **по строкам**.

Примеры:

* `events` по дате: “декабрь 2025”, “январь 2026”;
* `users` по регионам: “EU”, “US”, “APAC”;
* `orders` по диапазонам ID.

И вот **горизонтальное разрезание** — это как раз то,
из чего вырастают и **партиции**, и **шарды**.

---

#### 2.0.3. Партиционирование: одна таблица, много кусков

**Партиционирование (partitioning)** — это когда одна логическая таблица разбита на несколько физических кусков по какому-то признаку, но всё это живёт **в одном инстансе БД** и по возможности **прозрачно для приложения**:

* приложение всё так же делает `INSERT/SELECT` в `events`;
* БД сама решает, в какую партицию складывать и откуда читать.

Например, в Postgres:

```sql
CREATE TABLE events (
    id         bigserial PRIMARY KEY,
    user_id    bigint      NOT NULL,
    created_at timestamptz NOT NULL,
    payload    jsonb       NOT NULL
) PARTITION BY RANGE (created_at);
```

Создадим две партиции:

```sql
CREATE TABLE events_2025_12
    PARTITION OF events
    FOR VALUES FROM ('2025-12-01') TO ('2026-01-01');

CREATE TABLE events_2026_01
    PARTITION OF events
    FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');
```

Для приложения это всё ещё **одна таблица** `events`:

```sql
SELECT * FROM events
WHERE created_at >= now() - interval '1 day';
```

Postgres сам решает:

* в какие партиции лезть (partition pruning);
* какие партиции можно вообще не трогать.

Зачем это нам по боли:

* свежие партиции можно держать на SSD, старые — на другом tablespace/диске;
* можно **быстро дропать архивы**: `DROP TABLE events_2024_01` — и целый месяц/год данных исчез;
* VACUUM/индексы работают по кускам, а не по монстру на миллиард строк.

Это уже **горизонтальное партиционирование**, но **пока на одном кластере**.

---

#### 2.0.4. Горизонтальное партиционирование по ключу: RANGE, LIST, HASH

Основные способы деления:

##### RANGE — по диапазонам

* по дате (`created_at`);
* по ID (0–1M, 1M–2M).

Хорошо, когда:

* данные естественно упорядочены (временные серии, логи);
* удобно архивировать “старые хвосты”.

Боль:

* если все запросы идут только к “последней” партиции — именно она становится горячей;
* легко получить **hot partition**.

##### LIST — по конкретным значениям

* по `region`: `EU`, `US`, `APAC`;
* по `tenant_id`, если их немного и они стабильны.

Полезно, когда есть небольшой фиксированный набор категорий.

##### HASH — равномерное разбрасывание по ключу

В Postgres:

```sql
CREATE TABLE users (
    id    bigint PRIMARY KEY,
    email text NOT NULL
) PARTITION BY HASH (id);

CREATE TABLE users_p0
    PARTITION OF users
    FOR VALUES WITH (MODULUS 4, REMAINDER 0);

CREATE TABLE users_p1
    PARTITION OF users
    FOR VALUES WITH (MODULUS 4, REMAINDER 1);
-- и так далее
```

Под капотом — тот же самый `user_id % N`, который потом встретится в Dynamic Sharding.

Плюсы:

* равномерное распределение нагрузки и объёма (если ключ нормальный);
* нет одной “горячей” партиции.

Минусы:

* сложнее делать операции “по диапазону”;
* сложнее мигрировать/менять количество партиций.

Все эти штуки — **про то, как горизонтально разрезать таблицу**.
Пока это **partitioning**: всё может жить в одном Postgres-кластере.

---

#### 2.0.5. Когда partitioning превращается в sharding

Теперь аккуратно фиксируем терминологию.

**Партиционирование**:

* режем таблицу на куски (партиции);
* **всё остаётся на одном инстансе** БД;
* приложение по идее не знает, что внутри что-то порезано.

**Шардирование (sharding)**:

* режем данные на куски (шарды);
* **разносим эти куски по разным инстансам/серверам**;
* появляется задача **routing’а** — куда идти за этим конкретным ключом.

Простейший кейс:

* `users_shard_1`: Postgres #1, данные по `user_id % 4 = 0`;
* `users_shard_2`: Postgres #2, `user_id % 4 = 1`;
* `users_shard_3`: Postgres #3, `user_id % 4 = 2`;
* `users_shard_4`: Postgres #4, `user_id % 4 = 3`.

Грубо:

> Партиционирование — это про то, как порезать стол.
> Шардирование — про то, как эти куски столешницы развезти по разным складам.

**Зачем вообще идти до шардов, если есть партиции?**

* таблица/индексы уже **физически не лезут** на один сервер/в один диск нормально (или скоро не влезут);
* хотим увеличить **пропускную способность записи**:

    * один HDD даёт 100–200 MB/s, SSD — 500–600 MB/s,
    * несколько шардов на нескольких машинах могут писать **параллельно**;
* хотим распределить **CPU-нагрузку**;
* хотим геораспределение:

    * пользователи из EU → кластер в Европе;
    * US → кластер в США и т.д.

При этом:

* почти всегда шардирование идёт **в паре с репликацией**:

    * каждый шард имеет свои реплики;
    * иначе падение одной машины = смерть куска данных/сервиса.

Простейший “на коленке” routing-код:

```php
function getUserShardConnection(int $userId): PDO
{
    $shard = $userId % 4;

    return match ($shard) {
        0 => $this->connShard0,
        1 => $this->connShard1,
        2 => $this->connShard2,
        3 => $this->connShard3,
    };
}
```

Это уже шардирование:

* нам нужно **знать, куда идти** за конкретным пользователем;
* при rebalancing’е такая схема быстро превратится в ад — ровно об этом дальше в Dynamic Sharding.

---

#### 2.0.6. Шардирование по регионам и мапа-шардов

Пример из реальной жизни: гео-шардинг.

* Пользователи живут в разных регионах.
* Хотим:

    * чтобы европейцев обслуживал европейский кластер (меньше RTT);
    * американцев — американский;
    * азиатских — азиатский.

Наивный вариант — захардкодить mapping в коде:

```php
function getClusterForRegion(string $region): string
{
    return match ($region) {
        'EU'   => 'pg-eu-cluster',
        'US'   => 'pg-us-cluster',
        'APAC' => 'pg-apac-cluster',
    };
}
```

Более взрослый вариант: **таблица-шардмапа**:

```sql
CREATE TABLE shard_map (
    region      text PRIMARY KEY,
    dsn         text NOT NULL,
    is_readonly boolean NOT NULL DEFAULT false
);
```

Теперь приложение:

* по `region` сначала идёт в `shard_map`;
* получает DSN/кластер;
* и уже туда лезет за данными.

Это важный мостик к **Dynamic Sharding**:

> Как только вы вынесли “куда идти” из `% N` в явную конфигурацию/таблицу,
> вы можете начинать **переезжать** между шардами без перекомпиляции всего мира.

И ровно это мы будем разбирать в следующей части.

---

#### 2.0.7. Шардирование на уровне БД: Citus и друзья

Чтобы не казалось, что всё делается только через “PHP + 4 коннекшена”, фиксируем:

* в Postgres есть расширения, которые делают распределённую БД:

    * Citus — популярный пример;

* они:

    * сами создают шарды и распределяют их по воркерам;
    * держат у себя routing;
    * умеют выполнять **cross-shard** запросы (join/агрегации) под капотом.

Важно донести идею:

> Всё, что мы обсуждаем — “по какому ключу резать”, “как маршрутизировать”,
> “как жить с кросс-шардовыми операциями” — это не теоретический онанизм.
> Это реальные вопросы, на которые отвечают Citus, Vitess, Cockroach, Yugabyte и прочие движки.

---

#### 2.0.8. Мини-резюме перед углублением

Чтобы не потерять картину:

* Вертикальное разрезание — по столбцам, для оптимизации схемы и индексов.
* Горизонтальное разрезание — по строкам; наш основной фокус.
* Partitioning:

    * одна логическая таблица;
    * много партиций;
    * всё ещё один кластер/инстанс.
* Sharding:

    * те же куски, но разнесённые по разным инстансам;
    * нужен routing и отдельный разговор про миграции и согласованность.
* Ключи разрезания:

    * RANGE / LIST / HASH;
    * региональные мапы, user_id, tenant_id, временные диапазоны.
* Боль, от которой стартуем:

    * таблица перестаёт влезать на одну машину/диск/индекс;
    * хотим разделить горячее/холодное;
    * хотим разнести пользователей по регионам;
    * хотим увеличить пропускную способность, а один инстанс уже выжат.

И сверху ещё раз:

> Шардирование — не модная фича, а крайняя мера.
> Сначала выжимаем всё из одной БД и партиционирования,
> потом уже тащим в жизнь шардирование, rebalancing и все связанные приключения.
