## 2.4.5. Rebalancing и миграции без downtime

### 2.4.5.1. Зачем вообще нужен rebalancing

Мы уже частично затронули проблему перемещения данных между шардами в главе о динамическом шардировании и почему статическое шардирование нас не устраивает,
теперь поговорим об этом подробнее

Rebalancing — это ответ на один вопрос:

> “Как вернуть **здоровое распределение данных и нагрузки** по кластерам, не роняя прод?”

Почему layout со временем перестаёт быть адекватным?:

1. **Неравномерный рост данных (data skew)**  
   Один шард распух до терабайта, остальные по 100 ГБ.  
   → **Resharding внутри кластера**: переразбиваем диапазоны / бакеты между теми же нодами  
   (например, `[0..1M]` → `[0..500k]` + `[500k..1M]`).

2. **Горячие пользователи / категории / tenant’ы**  
   Один шард получает 80–90% RPS.  
   → **Targeted relocation / hot-tenant migration**: вывозим конкретные диапазоны или tenant’ов  
   на отдельные ноды / кластеры.

3. **Рост кластера (upscaling)**  
   Добавили новые шарды → их нужно заполнить частью существующих данных.  
   → **Upscaling rebalancing**: переносим часть диапазонов / бакетов на новые ноды.

4. **Сжатие кластера (downscaling)**  
   Убрали железо / хотим сократить расходы.  
   → **Downscaling rebalancing**: сливаем данные с “лишних” шардов на оставшиеся.

5. **Смена shard key (меняется доменная модель)**  
   Резали по `userId`, поняли, что правильнее по `sellerId` или `tenantId`.  
   → **Shard-key migration**: переносим данные в новую схему шардирования  
   (старый layout больше не нужен, дальше живём в новой модели).

Во всех этих сценариях миграции идут **на живой нагрузке** — без длительного downtime и без потерь/дубликатов,  
и именно это делает тему rebalancing одной из сложных частей шардирования.

## 2.4.5.3. Основные проблемы при миграции

Прежде чем обсуждать техники ребаланса, обозначим какие проблемы нас могут встретить в этом процессе

1. **Неконсистентность данных во время переноса**

   Если будем просто копировать строки, то

    * часть данных может оказаться только на старом;
    * часть — только на новом;
    * что-то задублируется.

2. **In-flight writes**

   Пока вы копируете 500 ГБ, в базу продолжают прилетать новые записи:

    * кто-то обновляет профиль;
    * кто-то создаёт заказ;
    * кто-то меняет статус.

   Если эти изменения не учесть — новый шард при переключении будет отставать.

3. **race conditions**

   Одна часть кода читает из старого, другая — уже из нового.
   Клиент делает два запроса подряд — и вдруг видит разные данные.

4. **Atomic cutover**

   Момент переключения со старого на новый шард должен быть

    * быстрым,
    * атомарным в пределах системы,
    * откатываемым.

5. **Нагрузка на сеть и базу**

   Неконтролируемый backfill (переливка) под нагрузкой может положить:

    * старый шард по диску/процессору
    * новый шард,
    * сеть

6. **Кеши**

   кеш может продолжить держать старые данные:

    * старые shard map’ы;
    * старые значения по ключам;
    * стейт в приложении.

   В итоге часть запросов идёт уже по новой схеме, часть — по старой.

Все это надо учитывать заранее, пофиксить будет проблематично

## 6. Общая структура online-миграции

схемы rebalancing’а обычно состоят из трех этапов

1. **Перенос bulk-данных (backfill)**
   Перекачиваем основной объём из старого layout’а в новый.

2. **Синхронизация изменений (CDC / журнал изменений)**
   Пока идёт backfill, фиксируем все новые изменения и доносим их до нового шарда.

3. **Переключение маршрутизации (cutover)**
   Переводим чтение/запись на новый layout, минимизируя окно гонок.

Примерная схема:

![Схема миграции между шарадами](assets/01-migration-flow.png)

Разберём по шагам.

1. Первый шаг - **Backfill (переливание)**  
   * читаем данные из старого layout чанками;
   * заливаем их в новый;
   * ограничиваем скорость, чтобы не уронить прод.
   * логируем прогресс (offsет/LSN/последний id).
   
   Результат: новый layout содержит всю историю до момента начала миграции.

2. Пока идёт backfill, в старую базу продолжают прилетать изменения.
   Чтобы их не потерять, включаем CDC(Change Data Capture), например Debezium, читаем WAL-логи, таким образом каждое `INSERT/UPDATE/DELETE` превращается в событие.

3. В это время отдельный воркер (Migrator) читает CDC-стрим и **реплеит** изменения в новый layout.
    Благодаря такому подходу у нас есть
   * гарантированная доставка;
   * правильный порядок событий для каждого ключа, например по LSN(Log Sequence Number) из  WAL-журнала ;
   Но нужна idempotent-обработка, чтобы повторы не ломали данные.

4. Благодаря LSN мы можем сверять отставание в записях между layout, и когда оно примерно равно нулю

5. Мы переходим к стадии **Cutover**. Для этого роутер/координатор переводит чтения/записи на новый layout;

6. Через некоторое время после стабилизации мы
   * отключаем мигратор и CDC для данного сценария;
   * чистим старый layout или оставляем как холодный архив.

Плюсы такого подхода:

* работает на сотнях гигабайт и миллиардах строк;
* модель консистентности прозрачная;
* in-flight writes не теряются.

Минусы:

* инфраструктурно тяжелее:

   * нужен CDC/репликация или брокер;
   * нужен мигратор с retry/идемпотентностью;
   * нужно мониторить лаг.

### Упрощённые варианты, которые вы услышите

Иногда вместо полноценного CDC используют более простые схемы:

* **Dual write**
  Пишем в старый и новый layout после backfill.
  Проблемы: нет журнала, нет гарантии порядка, легко получить рассинхрон и двойные апдейты.
  Годится только для маленьких, не критичных данных.

* **Write to new, read from old + мигратор**
  Новые записи идут в новый layout, читаем ещё из старого, фоновый мигратор подтягивает историю.
  Работает, если объёмы умеренные и можно пережить мелкие расхождения.

* **Routing first**
  Сначала меняем shard-map, горячие ключи сразу начинают жить в новом layout,
  хвост медленно вывозим фоном. Удобно для разгрузки горячих шардов, но сложнее reasoning по консистентности.

Ключевая мысль:  
эти техники — не “другие стратегии миграции”, а упрощённые реализации отдельных шагов
в общей схеме `backfill → догоняем изменения → cutover`.

### 2.4.5.6. Atomic cutover

Как бы вы ни переливали данные, в какой-то момент нужно сказать:

> “С этого момента **источник правды — новый layout**”.

Требования:

* короткое окно;
* понятная история “как откатиться назад”.

Типичные приёмы:

1. **Feature flag**

   * в коде есть флаг `useNewShardLayout`;
   * пока `false` — все запросы идут по старой схеме;
   * переключили на `true` — весь трафик ушёл на новую карту.

2. **Поколения (generation / epoch)**

   * у shard-map есть версия (`generation = 17`);
   * клиенты шлют запросы с “я работаю с поколением 17”;
   * при переключении на 18-е поколение оба layout’а могут временно жить параллельно,
     пока клиенты не обновили версию.

3. **Короткий freeze писателей**

   * на маленькое окно (десятки миллисекунд) блокируем запись:
      * флаг в роутере или блокировка в базе;
   * за это время обновляем shard-map / конфиг маршрутизации;
   * пользователи не успевают заметить, если окно <100ms.

4. **Write fencing**

   * запись проходит только при совпадении версии:

     ```sql
     UPDATE users
     SET ...
     WHERE id = :id AND generation = 18;
     ```

   * всё, что прилетело “в старую эпоху”, отклоняется или повторяется.

---

### 2.4.5.7. In-flight writes

Пока миграция идёт, система не стоит.

Чтобы не утонуть в артефактах:

* **идемпотентность операций**

   * повторение одного и того же события не должно ломать состояние;

* **write fencing / generation-checks**

   * писать только в актуальный layout;

* **drain очередей**

   * перед cutover вычищаем очереди задач/сообщений, которые пишут в старый layout;

* **короткие freeze-окна для критичных операций**

   * лучше 50 ms контролируемого фриза, чем вечный бардак в движении денег/остатков.

### 2.4.5.10. Итоги

Рано или поздно layout придётся менять:

* из-за роста;
* из-за косяков в выборе shard key;
* из-за смены продуктовых требований.

Нормальная стратегия:

* иметь базовое понимание **CDC + backfill** как канона;
* осознанно пользоваться упрощёнными схемами (dual write, write-to-new, routing-first) там, где масштаб и риск это позволяют;
* проектировать cutover и работу с in-flight writes так же серьёзно, как и саму схему шардирования.

Шардирование — это не только “как порезать”, но и “как потом это перерезать и не убить прод”.
