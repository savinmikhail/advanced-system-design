## 2.4.5. Rebalancing и миграции без downtime

### 2.4.5.1. Зачем вообще нужен rebalancing

Мы уже частично затронули проблему перемещения данных между шардами в главе о динамическом шардировании и почему статическое шардирование нас не устраивает,
теперь поговорим об этом подробнее

Rebalancing — это ответ на один вопрос:

> “Как вернуть **здоровое распределение данных и нагрузки** по кластерам, не роняя прод?”

Почему layout со временем перестаёт быть адекватным?:

1. **Неравномерный рост данных (data skew)**  
   Один шард распух до терабайта, остальные по 100 ГБ.  
   → **Resharding внутри кластера**: переразбиваем диапазоны / бакеты между теми же нодами  
   (например, `[0..1M]` → `[0..500k]` + `[500k..1M]`).

2. **Горячие пользователи / категории / tenant’ы**  
   Один шард получает 80–90% RPS.  
   → **Targeted relocation / hot-tenant migration**: вывозим конкретные диапазоны или tenant’ов  
   на отдельные ноды / кластеры.

3. **Рост кластера (upscaling)**  
   Добавили новые шарды → их нужно заполнить частью существующих данных.  
   → **Upscaling rebalancing**: переносим часть диапазонов / бакетов на новые ноды.

4. **Сжатие кластера (downscaling)**  
   Убрали железо / хотим сократить расходы.  
   → **Downscaling rebalancing**: сливаем данные с “лишних” шардов на оставшиеся.

5. **Смена shard key (меняется доменная модель)**  
   Резали по `userId`, поняли, что правильнее по `sellerId` или `tenantId`.  
   → **Shard-key migration**: переносим данные в новую схему шардирования  
   (старый layout больше не нужен, дальше живём в новой модели).

Во всех этих сценариях миграции идут **на живой нагрузке** — без длительного downtime и без потерь/дубликатов,  
и именно это делает тему rebalancing одной из сложных частей шардирования.

## 2.4.5.3. Основные проблемы при миграции

Прежде чем обсуждать техники ребаланса, обозначим какие проблемы нас могут встретить в этом процессе

1. **Неконсистентность данных во время переноса**

   Если будем просто копировать строки, то

    * часть данных может оказаться только на старом;
    * часть — только на новом;
    * что-то задублируется.

2. **In-flight writes**

   Пока вы копируете 500 ГБ, в базу продолжают прилетать новые записи:

    * кто-то обновляет профиль;
    * кто-то создаёт заказ;
    * кто-то меняет статус.

   Если эти изменения не учесть — новый шард при переключении будет отставать.

3. **race conditions**

   Одна часть кода читает из старого, другая — уже из нового.
   Клиент делает два запроса подряд — и вдруг видит разные данные.

4. **Atomic cutover**

   Момент переключения со старого на новый шард должен быть

    * быстрым,
    * атомарным в пределах системы,
    * откатываемым.

5. **Нагрузка на сеть и базу**

   Неконтролируемый backfill (переливка) под нагрузкой может положить:

    * старый шард по диску/процессору
    * новый шард,
    * сеть

6. **Кеши**

   кеш может продолжить держать старые данные:

    * старые shard map’ы;
    * старые значения по ключам;
    * стейт в приложении.

   В итоге часть запросов идёт уже по новой схеме, часть — по старой.

Все это надо учитывать заранее, пофиксить будет проблематично

## 6. Общая структура online-миграции

схемы rebalancing’а обычно состоят из трех этапов

1. **Перенос bulk-данных (backfill)**
   Перекачиваем основной объём из старого layout’а в новый.

2. **Синхронизация изменений (CDC / журнал изменений)**
   Пока идёт backfill, фиксируем все новые изменения и доносим их до нового шарда.

3. **Переключение маршрутизации (cutover)**
   Переводим чтение/запись на новый layout, минимизируя окно гонок.

Примерная схема:

![Схема миграции между шарадами](assets/01-migration-flow.png)

### 2.4.5.4. CDC + Backfill

Это пожалуй самый надежный, но довольно сложный паттерн

1. Первый шаг - **Backfill (переливание)**  
   * читаем данные из старого layout чанками;
   * заливаем их в новый;
   * ограничиваем скорость, чтобы не уронить прод.

2. С помощью CDC (Change Data Capture), например Debezium, слушаем WAL-логи, таким образом каждое `INSERT/UPDATE/DELETE` превращается в событие.

3. Далее отдельный воркер (Migrator) читает CDC-стрим и **реплеит** изменения в новый layout.
    Благодаря такому подходу у нас есть
   * гарантированная доставка;
   * правильный порядок событий для каждого ключа, например по LSN(Log Sequence Number) из  WAL-журнала ;
   Но нужна idempotent-обработка, чтобы повторы не ломали данные.

4. Благодаря LSN мы можем сверять отставание в записях между шардами, и когда оно приблизится к нулю

5. Мы переходим к стадии **Cutover**. Для этого роутер/координатор переводит чтения/записи на новый layout;

6. Через некоторое время после стабилизации мы
   * отключаем мигратор и CDC для данного сценария;
   * чистим старый layout или оставляем как холодный архив.

Плюсы такого подхода:

* нормально работает на больших объёмах;
* модель консистентности прозрачная;
* in-flight writes не теряются.

Минусы:

* инфраструктурно тяжелее:

   * нужен CDC/репликация или брокер;
   * нужен мигратор с retry/идемпотентностью;
   * нужно мониторить лаг.

### 2.4.5.5. Упрощённые схемы

Иногда масштаб задачи не оправдывает полноценный CDC-сетап.
Тогда используют более простые, но менее надежные схемы.

#### 1) Dual write

Самая часто предлагаемая идея:

> “Давайте просто писать и в старый, и в новый шард, а потом отключим старый”.

Алгоритм:

1. При каждом изменении приложение пишет **сразу в два места**: старый и новый layout.
2. Чтения какое-то время идут из старого (он источник правды).
3. Когда считаем, что новый шард “достаточно догнал”, переворачиваем чтения на него.
4. Старый layout выключаем или используем как временный бэкап.

Ключевое отличие от CDC:

* нет отдельного backfill-шага и журнала транзакций;
* приложение само пытается “повторить” запись в оба хранилища;
* порядок/успешность записей контролируется логикой бизнес-кода, а не репликацией.

Отсюда проблемы:

* **расхождение во времени**

   * запись в старый прошла, в новый упала с ошибкой;
   * retry сработал только на одном из шардов → состояния разошлись.

* **неидемпотентные операции**

   * `balance = balance + 100` легко превратить в `+200`;
   * сайд-эффекты (отправка писем, биллинг) могут сработать дважды.

* **частичное падение**

   * новый шард недоступен, старый жив;
   * приложение либо блокирует все writes, либо продолжает писать “куда получится” и получает рассинхрон.

Вывод:

> Dual write — допустимый костыль для маленьких миграций,
> но как базовый паттерн для серьёзного rebalancing’а — слабое решение.

На собесах от вас обычно ждут не “давайте сделаем dual write”,  
а внятное объяснение, **почему это опасно**, особенно без CDC и идемпотентности.

---

#### 2) “Write to new, read from old” + мигратор

Более аккуратный вариант без двойной записи:

* все **новые** записи сразу отправляем в новый layout;
* **чтения** до cutover идут из старого (источник правды один);
* фоновый мигратор переносит исторические данные из старого layout в новый;
* когда уверены, что новый layout догнал историю — переключаем чтения.

Плюсы:

* нет “стрельбы в обе базы” на каждом write;
* проще рассуждать о консистентности (истина до cutover — в старом месте).

Минусы:

* нужна отдельная логика мигратора и reconciliation’а;
* легко проморгать часть изменений, если мигратор кривой.

---

#### 3) “Routing first”

Сначала меняем маршрутизацию, потом вывозим хвост:

* shard-map / router начинает слать **новый трафик** сразу в новый layout;
* старый layout остаётся “держать хвост” (старые диапазоны/tenant’ов);
* фоновый процесс вывозит данные из старого в новый, пока старый не опустеет.

Плюсы:

* горячие ключи переезжают первыми (они начинают писаться в новый layout);
* не надо трогать write-path для всех операций сразу.

Минусы:

* сложнее reasoning по консистентности;
* нужен fallback: “если не нашли на новом — проверить старый”.

---

### 2.4.5.6. Atomic cutover

Как бы вы ни переливали данные, в какой-то момент нужно сказать:

> “С этого момента **источник правды — новый layout**”.

Требования:

* короткое окно;
* понятная история “как откатиться назад”.

Типичные приёмы:

1. **Feature flag**

   * в коде есть флаг `useNewShardLayout`;
   * пока `false` — все запросы идут по старой схеме;
   * переключили на `true` — весь трафик ушёл на новую карту.

2. **Поколения (generation / epoch)**

   * у shard-map есть версия (`generation = 17`);
   * клиенты шлют запросы с “я работаю с поколением 17”;
   * при переключении на 18-е поколение оба layout’а могут временно жить параллельно,
     пока клиенты не обновили версию.

3. **Короткий freeze писателей**

   * на маленькое окно (десятки миллисекунд) блокируем запись:
      * флаг в роутере или блокировка в базе;
   * за это время обновляем shard-map / конфиг маршрутизации;
   * пользователи не успевают заметить, если окно <100ms.

4. **Write fencing**

   * запись проходит только при совпадении версии:

     ```sql
     UPDATE users
     SET ...
     WHERE id = :id AND generation = 18;
     ```

   * всё, что прилетело “в старую эпоху”, отклоняется или повторяется.

---

### 2.4.5.7. In-flight writes

Пока миграция идёт, система не стоит.

Чтобы не утонуть в артефактах:

* **идемпотентность операций**

   * повторение одного и того же события не должно ломать состояние;

* **write fencing / generation-checks**

   * писать только в актуальный layout;

* **drain очередей**

   * перед cutover вычищаем очереди задач/сообщений, которые пишут в старый layout;

* **короткие freeze-окна для критичных операций**

   * лучше 50 ms контролируемого фриза, чем вечный бардак в движении денег/остатков.

---

### 2.4.5.8. Post-migration cleanup

После успешного cutover:

* вырубить или демонтировать старый layout (или явно пометить как архив);
* убедиться, что:
   * shard-map и конфиги обновлены везде;
   * кеши не держат старых маршрутов/значений;
* сравнить метрики “до/после”:

   * latency,
   * error-rate,
   * нагрузка по шардам.

---

### 2.4.5.9. Анти-паттерны

Короткий список вещей, которые почти всегда заканчиваются плохо:

1. **“Выключим всё ночью и мигрируем SQL-скриптом”**

   Для живого бизнеса это легко превращается в часы простоя
   с неясной точкой возврата.

2. **Один гигантский SQL на сотни гигабайт**

   `INSERT INTO ... SELECT ...` “за один заход”.  
   Любая ошибка = откат не на секунды, а на ночь.

3. **Клиент знает, на какой шард идти**

   Логика шардирования зашита в мобильные/веб-клиенты.  
   Любой rebalancing теперь = “обновить всех клиентов”.

4. **“Сначала убьём старый шард, потом перенесём данные”**

   В момент миграции у вас нет источника правды.  
   Любой баг в переносе = данные потеряны навсегда.

---

### 2.4.5.10. Итоги

Рано или поздно layout придётся менять:

* из-за роста;
* из-за косяков в выборе shard key;
* из-за смены продуктовых требований.

Нормальная стратегия:

* иметь базовое понимание **CDC + backfill** как канона;
* осознанно пользоваться упрощёнными схемами (dual write, write-to-new, routing-first) там, где масштаб и риск это позволяют;
* проектировать cutover и работу с in-flight writes так же серьёзно, как и саму схему шардирования.

Шардирование — это не только “как порезать”, но и “как потом это перерезать и не убить прод”.
