#### 5.c.0. Рамка: “всё — trade-off” + SLO

Коротко:

* цитата Марка Ричардса: *“Everything in software architecture is a trade-off.”*

* связка с предыдущими частями главы:

  > Мы уже поговорили про кэш, транзакции, шардирование, хвосты и throughput.
  > Теперь честно посмотрим, **чем мы платим** за производительность, надёжность и масштабируемость: CPU, памятью, сетью, сложностью и деньгами.

* ввести SLO/SLA очень коротко:

    * SLO = внутренняя целевая планка (p95, аптайм).
    * SLA = маркетинговое обещание.
    * **Все дальнейшие решения — “как уложиться в SLO так, чтобы не разориться и не убить команду сложностью.”**

Дальше — блоки по ресурсам.

---

#### 5.c.1. CPU & Concurrency: эффективность vs предсказуемость

Тут логично использовать теорию очередей и “кривую с коленом”.

Боли:

* “Давайте грузить CPU на 90–100%, зачем простаивает?”
* “Почему при 80% загруженности всё ок, а при 90% p99 превращается в ад?”

Содержание:

* Очень коротко пересобрать идею из queueing theory:
  при ρ → 1 очередь и время ожидания → ∞.
* Показать knee curve (то, что ты нашёл) и сказать в лоб:

  > Высокая утилизация CPU “почти под 100%” красиво выглядит на графиках,
  > но математически означает бесконечно растущую очередь и хвост.

Trade-off:

* latency-sensitive сервисы:

    * держим **headroom по CPU**, допускаем “недоиспользование” железа;
    * выигрываем в p95/p99 и предсказуемости.
* batch/аналитика:

    * можно добивать CPU почти в потолок;
    * хвост не так важен, важна цена/объём работы.

Вывод: **“Оптимальное использование CPU” ≠ “вечно 95–100% загрузки”**.

---

#### 5.c.2. Память и кэш: hit ratio vs стоимость vs сложность

Боли:

* “Повесь кэш — будет быстро.”
* “Давайте держать всё в памяти, RAM дешёвая.”
* А в итоге:

    * жирные инстансы;
    * GC-паузы;
    * cache stampede;
    * сложная инвалидация.

Содержание:

* Кэш как способ “купить” latency/throughput за память и сложность.
* Trade-off:

    * больше памяти / больше кэша → меньше нагрузка на БД/внешние API;
    * но:

        * дороже инфраструктура;
        * сложнее инвалидация;
        * риск stale-даты и непредсказуемых хвостов при miss’ах.

Здесь можно мельком упомянуть request coalescing / per-key mutex, но без глубокого техразбора (он у тебя в части про кэш).

---

#### 5.c.3. Storage & Data Layer: надёжность vs latency vs стоимость

Боли:

* “Сделай, чтобы база не падала” → три реплики, кворум, синхронная репликация.
* Потом внезапно:

    * записи стали медленнее,
    * latency выросла,
    * инфраструктура стоит ×2–3.

Содержание:

* Репликация:

    * Read-heavy: реплики помогают throughput, latency чтения падает.
    * Write-heavy + строгая консистентность: каждая реплика = +latency, −throughput.
* Индексы / материализованные вьюхи:

    * индекс = быстрее чтение, дороже запись;
    * матвью = быстрые выборки, но сложная инкрементальная поддержка.

Trade-off:

* **Durability / Availability** vs latency/cost.
* **Удобство запросов** (индексы, денормализация) vs write-throughput и сложность обновлений.

Всё это напрямую связано с тем, что ты уже рассказывал в частях про транзакции и шардирование — здесь ты это “собираешь” под углом ресурсов.

---

#### 5.c.4. Сеть и топология: многозонность vs RTT vs деньги

Боли:

* “Давайте сделаем мульти-AZ / мульти-регион, чтобы не падать.”
* Потом:

    * растут round-trip times;
    * кворумы начинают страдать;
    * счёт за трафик и cross-region межсерверку больно кусается.

Содержание:

* Co-location:

    * складываем всё в одном регионе → меньше latency, дешевле трафик;
    * но хуже отказоустойчивость (AZ/region failure).
* Multi-AZ / multi-region:

    * лучше доступность;
    * но:

        * RPC растягиваются;
        * кворумы на запись (R+W>N) удлиняют запрос;
        * дорого по деньгам.

Trade-off:

* **Availability / DR** vs latency vs cost.
* Как это стыкуется с SLO: если у тебя SLO по аптайму 99.99% и строгая RTO/RPO — да, ты сознательно покупаешь большие RTT и счет за сеть.

---

#### 5.c.5. Изоляция vs Utilization: noisy neighbor

Боли:

* общий кластер для всего:

    * “ресурсы используются эффективнее”;
    * но:

        * noisy neighbors;
        * нестабильные хвосты;
        * “по ночам, когда ETL, всё API лагает”.

Содержание:

* Shared пул:

    * дёшево, хорошая средняя утилизация;
    * но хвост непредсказуем, от соседей прилетает боль.
* Выделенные кластеры / ноды:

    * тишина, предсказуемый p95/p99;
    * но ресурсы местами тупо простаивают.

Trade-off:

* плачемся в cost-отчёте vs плачемся в Grafana по p99.
* для latency-critical:

    * лучше отдельные пулы / ноды / кластера;
* для вторичного:

    * можно жить в зашумлённой общаге.

---

#### 5.c.6. Сложность vs “экономия”

Боль:

* “Давайте придумаем умный автоскейлинг, динамическую аллокацию лимитов, 5 уровней приоритетов, 3 очереди, 10 сигналов для контроллера…”
* В итоге:

    * никто не понимает, как это работает,
    * чинить некому,
    * баги проявляются только под нагрузкой.

Содержание:

* Любая “умная” стратегия оптимизации ресурсов = ещё один слой сложности.
* Trade-off:

    * простая архитектура с немного overprovisioning’ом:

        * дороже по железу,
        * дешевле по мозгам и рискам;
    * навороченная, сверхоптимизированная:

        * дешевле по железу,
        * дороже по поддержке, рисков куча.

Здесь можно красиво связать с First Law:

> Хотите меньше платить за железо — будете больше платить мозгами и временем команды.
> Хотите простую систему — будете переплачивать за некоторый запас ресурсов.

---

#### 5.c.7. Финал: как принимать решения

Закрывающий блок, вообще без формул:

* Всё, что вы делаете с ресурсами — это **осознанное движение по осям**:

    * эффективность vs предсказуемость;
    * latency vs cost;
    * availability vs latency;
    * utilization vs isolation;
    * сложность vs стоимость железа.
* Решение должно быть привязано к:

    * SLO (что мы обязуемся по задержке/доступности),
    * деньгам (сколько мы готовы платить),
    * рискам (что будет, если всё-таки упадёт).

Фраза в духе:

> Нет “правильных” решений. Есть честно выбранные компромиссы между производительностью, стоимостью, надёжностью и сложностью — и понимание, **кому и чем вы за них заплатите**.
