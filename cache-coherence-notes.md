# Часть 1. Продвинутое кэширование и консистентность кэша  
## План всей части (A–C) и опорные блоки

Этот файл — рабочие заметки для подготовки сценария. README.md ассистент не трогает, сюда можно копировать/адаптировать тезисы.

Важно: здесь сразу учитываем фидбек модерации по предыдущим главам.

- Никакой «воды» и голых перечислений стратегий: каждый пункт должен иметь «что это / зачем / где в работе / где на собесе / как на схеме».
- Всегда есть реальный кейс (желательно один домен на протяжении части — интернет‑магазин/маркетплейс/доставка).
- Для любых списков вопросов — есть примеры ожидаемых ответов и пояснение, как они влияют на архитектуру.
- Меньше терминов, больше глубины: выбираем 2–3 ключевых паттерна, остальные упоминаем вскользь или выносим в «для любопытных».

---

## Что уже сказано про кэш в главах 1–2

До нашей части курс уже упоминает кэш, но без глубокой проработки:

- В главе 1:
  - на уровне архитектурной схемы: «микросервис общается с базой данных и/или кэшем»;
  - один пример: «часто запрашиваемые данные (история заказов) могут храниться в кэше, это поможет сократить задержки».
- В главе 2:
  - блок «Данные и кэш»: PostgreSQL как основная база, реплики для чтения, Redis как кэш для «горячих» данных (ближайшие выгульщики, сессии), TTL, S3 для файлов;
  - блок «Чтение и запись»: «для чтений подключаем реплику базы и кэш Redis»;
  - блок «Масштабирование кэша и очередей»: Redis как кэш, кластер Redis для горизонтального масштабирования.

То есть:
- уже показано, что кэш существует и что он «ускоряет» и снимает нагрузку;
- упомянут Redis, TTL и масштабирование кэша;
- но почти нет:
  - формального определения и модели «что такое кэш и где он живёт в системе»;
  - терминов и паттернов (cache-aside, write-through, stampede и т.п.);
  - подробного разбора проблем (устаревшие данные, инвалидация, гонки, dogpile);
  - разговоров про многослойное кэширование, тегирование и версионирование.

Вывод: в нашей части не нужно объяснять кэш «с нуля для джунов», но стоит дать короткий, практический advanced‑рефреш, который логично продолжит главу 2 и подведёт к cache coherence.

---

## Общий каркас части 1 и домен примеров

- Домен: интернет‑магазин / маркетплейс (уровня Ozon/Wildberries, но без брендов), где есть:
  - каталог товаров с фильтрами и сортировкой;
  - карточка товара с ценой, остатками на складе, рейтингом и отзывами;
  - корзина и оформление заказа;
  - личный кабинет с историей заказов;
  - промо‑механики (скидки, персональные рекомендации).
- Структура части:
  - Блок 1 — модель кэша и базовые паттерны (общий ввод, единая терминология для A–C);
  - Блок 2 (A) — cache coherence в распределённых системах;
  - Блок 3 (B) — многоуровневое кэширование и оптимизации;
  - Блок 4 (C) — сложные проблемы кэширования и практические кейсы.
- Нарратив части:
  - короткий рекап и «боль» от кэша → модель кэша → cache coherence как главный концептуальный блок → многоуровневые оптимизации → «тёмная сторона» и собес.

---

## Блок 1. Модель кэша и базовые паттерны (общий ввод ко всей части)

Этот блок идёт в начале части 1 и «склеивает» подпункты A, B, C. Время: 5–7 минут.
Метазаметка: в сценарии сам блок должен быть короче (3–5 минут) — в него попадают пункты 1–2 и мост к подпунктам; детали из пунктов 3–7 можно разнести в A/B/C как материал для примеров и углублений.

### 1. Кэш как часть архитектуры, а не просто «ускоритель»
   - Что такое кэш в терминах архитектуры: «быстрый, ограниченный, потенциально устаревающий слой рядом с медленным, но источником истины».
   - Где он обычно стоит: перед базой, перед сторонним API, перед тяжёлой бизнес‑логикой.
   - Какие метрики и ограничения важны: latency, hit rate, пропускная способность, объём, TTL.
   - Базовые термины, на которые дальше будем опираться:
     - `cache hit` / `cache miss`;
     - hot key vs холодный кэш;
     - TTL, эвикция, stale data.

### 2. Слои кэширования в реальных системах
   - Браузерный кэш / HTTP‑кэш (ETag, Cache-Control).
     - Что может храниться:
       - статические ресурсы (JS, CSS, шрифты, картинки, иконки);
       - ответы API, если помечены подходящими заголовками;
       - offline‑ресурсы и данные в Cache Storage через Service Worker.
     - Как инвалидируется:
       - заголовки `Cache-Control` (`max-age`, `no-store`, `no-cache`, `must-revalidate`);
       - условные запросы с `ETag` / `If-None-Match`, `Last-Modified` / `If-Modified-Since`;
       - версионирование статических файлов (hash в имени: `app.[hash].js`) и cache busting;
       - обновление Service Worker’а и явная очистка/миграция Cache Storage.
   - CDN / edge‑кэширующие прокси.
   - Кэш на уровне приложения (in‑process) — LRU в памяти сервиса.
   - Распределённый кэш (Redis/Memcached‑кластер).
   - Кэш на стороне БД / индексные структуры / материализованные представления.
   - Где именно в нашем домене (интернет‑магазин/маркетплейс) эти слои появляются на схеме:
     - браузерный кэш — статика, куски каталога, изображения;
     - CDN/edge — статика, страницы каталога и карточек, медиа;
     - in‑process кэш — крошечные справочники, настройки витрины, права;
     - Redis/Memcached — сессии, содержимое корзин, популярные товары, агрегаты по каталогу;
     - БД‑уровень — индексы по товарам, материализованные представления для отчётов/витрин.
   - В сценарии важно показать одну общую схему слоёв; подробности про HTTP‑кэш и Service Worker можно держать как запасной материал.

### 3. Зачем кэш реально используют (use‑cases)
   - Разгрузка других систем:
     - снижение нагрузки на основную БД (горячие ключи, тяжёлые JOIN/агрегации);
     - снижение количества обращений к внешним API.
   - Ускорение ответов для горячих чтений (карточка пользователя, список ближайших объектов, состояние заказа).
   - Переиспользование дорогих вычислений:
     - предрасчитанные отчёты, агрегации, подборки рекомендаций;
     - сохранение результатов тяжёлых алгоритмов матчинга.
   - Особые кейсы: rate limiting, feature‑флаги, флаги доступности ресурсов.

### 4. Основные проблемы кэширования
   - Устаревшие данные (stale reads) и рассинхронизация с источником.
   - Cache stampede/dogpile (thundering herd problem) — упомянуть как типичную проблему, без детального разбора (подробно в блоке 4).
   - Тёплый/холодный кэш, прогрев, ресет кластера кэша.
   - Ограниченный объём и эвикция: что и почему будет выбрасываться.
     - стратегии вытеснения: LRU, LFU, FIFO, TTL-only, random eviction;
     - как выбор стратегии связан с паттерном доступа (горячие ключи, хвост распределения).

### 5. Базовые паттерны взаимодействия с кэшем
   - Cache-aside (lazy loading) — самый частый кейс; как это выглядит в коде/на схеме.
   - Cache-ahead / pre-warming — когда мы заранее кладём данные в кэш, предвосхищая запросы (например, популярные маршруты/подборки).
   - Read-through / write-through / write-behind — чем отличаются, когда применимы.
   - 1–2 простые flow‑диаграммы «запрос → кэш → БД» без длинных списков.
   - В сценарии детально показываем только cache‑aside (flow и псевдокод), остальные паттерны используем как фон в блоках A–C.

### 6. Инвалидация и управление свежестью
   - TTL как тупой, но дешёвый инструмент; где этого достаточно, а где — нет.
   - Явная инвалидация по событиям: pub/sub, сообщения от БД (CDC), доменные события.
   - Частичные инвалидации (по ключу, по тегу, по «версии данных»).

### 7. Тегирование и версионирование кэша
   - Идея тегов: группировать связанные ключи (например, все данные пользователя) для массовой инвалидации.
   - Версионирование кэша: включение версии схемы/данных в ключ (или отдельное поле) для безопасных деплоев и миграций.
   - Как это помогает при изменении бизнес‑логики и схемы БД, не убивая сразу весь кластер кэша.

### 8. Мост к последующим подпунктам
   - Подводка: теперь у нас не один кэш, а пирамидка слоёв, в каждом из которых лежат копии одних и тех же данных.
   - Вопросы:
     - как сделать так, чтобы эти копии не противоречили друг другу (подводка к подпункту A — cache coherence);
     - как именно распределить данные по уровням кэша и что где держать (подводка к подпункту B — многоуровневое кэширование);
     - что делать, когда всё это ломается под нагрузкой (подводка к подпункту C — сложные проблемы кэширования).

---

## Блок 2 (A). Cache Coherence в распределённых системах

Ориентир: 10–15 минут, можно ужимать/расширять.

1. **Зачем вообще говорить про cache coherence в распределённых системах**
   - Приводим короткий инцидент из маркетплейса: пользователь меняет адрес доставки или способ оплаты, а часть интерфейса продолжает показывать старые данные.
   - Под капотом: профиль хранится в БД, локальном кэше сервиса, общем Redis и частично в CDN/браузере — слои обновляются в разное время.
   - У нас не один кэш, а много: локальные кэши сервисов, общий Redis/Memcached, CDN, браузер и т.д.
   - Каждая новая копия ускоряет чтения, но увеличивает риск противоречий.
   - Интуитивная проблема: «почему пользователю показывают старые данные, хотя запись в БД уже обновилась?».

2. **Определения: cache coherence vs consistency**
   - Cache coherence — про согласованность _копий одного и того же объекта_ между разными кэшами.
   - Отстроиться от «консистентности данных в БД» и от CAP-теоремы.
   - Условие: «нет двух кэшей с противоречащими значениями» + обсудить, насколько быстро мы этого требуем.

3. **Мысленная модель: аналогия с процессорными кэшами, но в более «грязном» мире**
   - В CPU есть протоколы MESI и жёсткий порядок операций.
   - В распределённой системе:
     - ненадёжная сеть,
     - непредсказуемые задержки,
     - нет глобальных часов.
   - Хочется ощущения «как будто данные в одном месте», но платим ростом сложности и latency.

4. **Типичные архитектуры кэшей и где там всплывает coherence**
   - Один общий распределённый кэш-кластер (Redis/Memcached) поверх БД: coherence проще, но есть TTL, репликация, шардирование.
   - Многоуровневый кэш:
     - L1 — локальный in-memory кэш в каждом сервисе;
     - L2 — общий Redis;
     - L3 — БД.
   - CDN / edge-кэши поверх API.
   - На каждом уровне — свой компромисс между свежестью, latency и сложностью.

5. **Механизмы обеспечения согласованности (2–3 базовые стратегии)**
   - Разбираем не весь зоопарк, а несколько характерных подходов:
     - TTL‑only / «ленивая» согласованность: дешёво, просто, но позволяет жить со stale данными (подходит для лент, счётчиков).
     - Явная инвалидация по событиям (pub/sub, message bus, CDC): дороже в реализации, но даёт предсказуемое окно рассинхрона.
     - Lease‑ / token‑based подходы: только владелец «лизинга» имеет право обновлять кэш; связываем с fencing tokens и лизинговыми блокировками.
   - Показываем, как выбор стратегии записи (cache-aside, read-/write-through, write-behind) влияет на согласованность между уровнями кэша и БД.
   - Инвалидация vs обновление:
     - связываем с ранее рассказанными TTL и событийной инвалидацией (pub/sub, message bus, CDC);
     - объясняем, как задержки в этих механизмах превращаются в конкретные inconsistency‑кейсы.
   - Push vs pull:
     - кэш сам запрашивает обновления (pull) vs получает события извне (push) — как это влияет на задержку до «согласованного» состояния.
   - Здесь же можно мостиком сослаться на будущий инцидент со split‑brain в блоке C.

6. **Сложные кейсы и баги**
   - Одновременные запросы: гонки при записи, lost update, грязное чтение.
   - Split-brain и расхождение между узлами кэша.
     - отметить, что в блоке 4 будет живой инцидент со split-brain.
   - Примеры:
     - профиль пользователя;
     - баланс/лимиты;
     - корзина/остатки товара;
     - rate limiting.

7. **Trade-off’ы: цена сильной когерентности**
   - Сильная когерентность = больше синхронизации между узлами, выше latency и стоимость.
   - Где достаточно eventual coherence (лента, счётчики лайков).
   - Где нужна «почти» strong coherence (деньги, лимиты, инвентарь) и какие паттерны помогают:
     - версионирование (ETag, версии записей);
     - CAS/compare-and-set;
     - fencing tokens, лизинговые блокировки.

8. **Наблюдаемость и тестирование когерентности**
   - Метрики:
     - доля stale reads;
     - hit/miss каждого уровня кэша;
     - частота инвалидаций.
   - Chaos/latency injection: как проверить, что при задержках и падениях модель согласованности не разваливается.
   - Типичные вопросы на собеседовании:
     - какие гарантии по свежести данных в кэше вы даёте?
     - как убедиться, что кэш и БД не расходятся?
   - Визуализации: схема multi‑level‑кэша с подсвеченными местами рассинхрона, timeline гонки при инвалидации и небольшая таблица «паттерн coherence / плюсы / минусы».

---

## Блок 3 (B). Многоуровневое кэширование и оптимизации

Ориентир: 10–15 минут.

1. **Многоуровневая схема кэширования в нашем домене**
   - Конкретная картинка: клиент → CDN/edge → API‑шлюз → backend‑сервисы (с L1‑кэшами) → Redis‑кластер → БД/хранилища.
   - Что на каком уровне держим: статика, результаты API, агрегаты, сессии, справочники и т.п.
   - Берём ту же схему, что и в блоке 1, но теперь смотрим на неё через призму latency и стоимости.
   - Визуально: одна большая схема + простая heatmap «тип данных × слой кэша», которая помогает обсуждать, что куда выгодно складывать.

2. **Чтения через несколько уровней кэша**
   - Типичный read‑flow: клиентский кэш → edge → L1 → L2 → БД.
   - Где хотим максимальный hit‑rate и почему (обычно L1+L2).
   - Как multi-level кэш влияет на tail latency: где выгодно положить ещё один слой, а где нет.

3. **Записи и обновления в многоуровневой системе**
   - Порядок обновления слоёв: сначала источник истины, потом инвалидация/обновление кэшей.
   - Выбор стратегии: «invalidate‑all» vs «invalidate‑by‑key/tag» vs «lazy refresh on next read».
   - Тегирование и группировка ключей:
     - зачем группировать связанные ключи (все данные пользователя, все данные товара);
     - как тегированная инвалидация помогает при массовых изменениях (например, при деактивации продавца).
   - Версионирование кэша:
     - включение версии схемы/данных в ключ или отдельное поле;
     - связь с blue‑green деплоем и dual‑write: старая и новая модель живут параллельно на разных наборах ключей.
   - Trade‑off’ы: чем больше уровней и «умнее» инвалидация, тем сложнее поддерживать согласованность и отлаживать баги.

4. **Оптимизации под реальные паттерны трафика**
   - Горячие ключи (hot keys) и их обработка:
     - распределение нагрузки по нескольким шардам/репликам кэша;
     - запросы через отдельный слой/сервер для горячих данных.
   - Cache-ahead / pre-warming:
     - прогрев популярных маршрутов/точек/подборок перед пиком;
     - как не «убить» БД прогревом.
   - Request coalescing / single flight:
     - если 100 запросов одновременно прилетели к одному ключу — даём в БД сходить только одному.

5. **Эвикция и управление памятью на разных уровнях**
   - Почему разные уровни могут использовать разные стратегии:
     - LRU/LFU в in‑process кэше;
     - TTL + LRU в Redis;
     - короткий TTL на edge‑уровне.
   - Как читать и использовать статистику по эвикциям и hit‑rate (о чём спрашивают на собесе).

6. **Наблюдаемость и настройка**
   - Какие метрики нужны именно для multilevel:
     - hit‑rate по каждому слою;
     - количество invalidations/second;
     - распределение latency по слоям.
   - Как по метрикам принимать решения: где добавить/убрать уровень, где поменять TTL.

---

## Блок 4 (C). Сложные проблемы кэширования и практические кейсы

Ориентир: 10–15 минут. Здесь логично собрать «тёмную сторону» паттернов из блоков 1–3 и показать, как это обсуждать на собесе.

1. **Thundering herd / cache stampede**
   - Сценарий: ключ протух, десятки тысяч запросов одновременно лезут в БД.
   - Паттерны решения:
     - mutex/lock вокруг заполнения кэша (single flight);
     - «заглядывание вперёд» по TTL (early refresh);
     - jitter/randomized TTL, чтобы ключи не истекали одновременно.

2. **Управление устаревшими данными**
   - Где можно жить с сильно устаревшими данными (лента, счётчики) и почему.
   - Где нельзя (деньги, лимиты, баланс, инвентарь) и как тогда строим кэш:
     - короткие TTL + строгие проверки по БД;
     - хранение только вспомогательной информации в кэше;
     - использование версий/ETag’ов.

3. **Инциденты из продакшена (примерно 2–3 истории)**
   - Ошибка инвалидации: кэш показывает старую цену/баланс.
   - Неправильный TTL/эвикция → кэш постоянно холодный, система тормозит.
   - Split-brain в кластере кэша → разные ответы для разных пользователей (связать с обсуждением из блока 2).
   - Для каждой истории:
     - как выглядели симптомы;
     - что оказалось root cause;
     - какие изменения в архитектуре/паттернах помогли.

4. **Кэш и собеседования по system design**
   - Типовые вопросы:
     - «Как будете использовать кэш, чтобы выдержать X rps?»;
     - «Что будете кэшировать первым делом, а что точно не будете?»;
     - «Как убедитесь, что кэш и БД не расходятся на критичных данных?».
   - На что обычно смотрят интервьюеры:
     - понимаете ли вы trade‑off’ы между свежестью и производительностью;
     - умеете ли объяснять стратегию инвалидации и поведение при сбоях;
     - упоминаете ли thundering herd, hot keys, observability.
   - Делаем мини‑сценарий диалога:
     - пример «плохого» ответа уровня «поставлю Redis перед БД»;
     - пример «хорошего» ответа, где кандидат сначала уточняет тип данных, SLA по свежести и latency, а уже потом предлагает многоуровневую схему кэширования.

5. **Специфические tricky‑кейсы**
   - Кэширование негативных и «пустых» результатов:
     - 404, пустые поисковые выдачи, «у пользователя нет заказов»;
     - почему это сильно разгружает БД под нагрузкой и какие тут грабли.
   - Кэш и права доступа / feature flags:
     - кэширование ACL, ролей, признаков включённых фич;
     - чем опасны «долгоживущие» ключи, если права уже поменялись.
   - Multi‑tenant‑системы:
     - пример ошибки, когда забыли положить tenant‑id в ключ;
     - к чему это приводит в проде и почему это любимый вопрос на собеседовании.

6. **Кэш в контексте деплоев и миграций**
   - Как вести себя при смене схемы данных или бизнес‑логики:
     - версионирование ключей и постепенное выключение старой схемы;
     - связка с blue‑green деплоем и dual‑write.
   - Какие вопросы задать себе перед релизом, если кэш активно используется.

7. **Чеклист «взрослого» отношения к кэшу**
   - 5–7 вопросов, на которые вы отвечаете перед запуском:
     - где источник истины для этих данных и какая допустимая задержка до согласованности;
     - что именно и где кэшируем, а что сознательно не кэшируем;
     - как устроена инвалидация и что будет при падении любого слоя;
     - как измеряем hit‑rate, thundering herd, горячие ключи;
     - что произойдёт при полном сбросе кэша под нагрузкой.
   - Этим чеклистом удобно заканчивать часть и делать плавный мост к следующей главе.

---

## Ссылки на материалы

Подборка для углубления, чтобы оттуда вытаскивать идеи, примеры и формулировки.

### Русскоязычные источники

- **Когерентность кэша — Википедия**  
  Базовые определения и терминология.  
  https://ru.wikipedia.org/wiki/Когерентность_кэша

- **«Мифы о кэше процессора, в которые верят программисты» (Habr)**  
  Хорошее интуитивное объяснение когерентности кэша на уровне процессора, можно брать метафоры и объяснения.  
  https://habr.com/ru/articles/354748/

- **«Проектирование эффективной системы кэширования» (Habr)**  
  Обзор видов кэша, многоуровневого кэширования и distributed cache; хороший фон для твоей «продвинутой» части.  
  https://habr.com/ru/articles/853340/

- **«Что, если выкинуть все лишнее из базы в распределенный кэш» (ЮMoney + Hazelcast)**  
  Реальный кейс с распределённым кэшем, split-brain, согласованностью и проблемами под высокой нагрузкой.  
  https://habr.com/ru/companies/yoomoney/articles/332462/

- **«Как распилить монолит на сервисы и сохранить целостность данных» (T‑Банк)**  
  Про микросервисы, целостность данных и роль распределённого кэша в этом всём.  
  https://habr.com/ru/companies/tbank/articles/474994/

(Дополнительно можно поискать на YouTube по запросам «кэширование распределённые системы», «cache invalidation системный дизайн» — там есть доклады от Тинькофф, Avito, Яндекс, Ozon.)

### Англоязычные источники — распределённый кэш и согласованность

- **Martin Kleppmann — Designing Data‑Intensive Applications**  
  Главы про репликацию, кэширование и согласованность; хорошая база для понимания роли кэша в распределённых системах.  
- **Meta Engineering — «Cache made consistent»**  
  История о том, как Facebook/Meta обеспечивали согласованность большого распределённого кэша.  
  https://engineering.fb.com/2022/06/08/core-infra/cache-made-consistent/

- **«Distributed Caching Woes: Cache Invalidation» (Medium)**  
  Разбор боли с cache invalidation в распределённой системе и типовых паттернов.  
  https://medium.com/systems-architectures/distributed-caching-woes-cache-invalidation-c3d389198af3

- **ByteByteGo — «Distributed Caching: The Secret to High-Performance Systems»**  
  Обзор distributed cache, паттернов кэширования и проблем согласованности/инвалидации.  
  https://blog.bytebytego.com/p/distributed-caching-the-secret-to

- **Distributed cache — Wikipedia**  
  Общее представление о distributed cache, упоминание coherence, cache stampede и т.п.  
  https://en.wikipedia.org/wiki/Distributed_cache

- **Паттерны кэширования в Redis**  
  Официальные или околоредисные материалы по cache-aside, write-through, write-behind, read-through.  
  (Поиск: “Redis caching patterns” — актуальный раздел документации Redis.)
- **Инженерные блоги (Discord, крупные маркетплейсы, сервисы доставки)**  
  В блогах этих команд регулярно выходят разборы инцидентов с кэшем, stampede и split-brain — хороший источник живых историй и графиков для иллюстраций.

### Видео

- **«Effective Caching Strategies for Distributed Systems» (YouTube)**  
  Доклад про стратегии кэширования в распределённых системах, проблемы согласованности.  
  https://www.youtube.com/watch?v=vaUozFw-Y9k

- **«How Do You Achieve Cache Coherence In Distributed Systems» (YouTube)**  
  Короткое видео именно про cache coherence в распределённом контексте.  
  https://www.youtube.com/watch?v=L4OyfmIy-xU

---

Дальше по этому файлу можно:
- уточнять/расширять план (добавлять конкретные примеры и истории);
- помечать, какие ссылки реально использованы в сценарии;
- набрасывать варианты формулировок для сценария, которые потом переписываются под твой голос.
