# Часть 1. Продвинутое кэширование и консистентность кэша  
## План всей части (A–C) и опорные блоки

Этот файл — рабочие заметки для подготовки сценария. README.md ассистент не трогает, сюда можно копировать/адаптировать тезисы.

Важно: здесь сразу учитываем фидбек модерации по предыдущим главам.

- Никакой «воды» и голых перечислений стратегий: каждый пункт должен иметь «что это / зачем / где в работе / где на собесе / как на схеме».
- Всегда есть реальный кейс (желательно один домен на протяжении части — самокаты/такси/маркетплейс/доставка).
- Для любых списков вопросов — есть примеры ожидаемых ответов и пояснение, как они влияют на архитектуру.
- Меньше терминов, больше глубины: выбираем 2–3 ключевых паттерна, остальные упоминаем вскользь или выносим в «для любопытных».

---

## Что уже сказано про кэш в главах 1–2

До нашей части курс уже упоминает кэш, но без глубокой проработки:

- В главе 1:
  - на уровне архитектурной схемы: «микросервис общается с базой данных и/или кэшем»;
  - один пример: «часто запрашиваемые данные (история заказов) могут храниться в кэше, это поможет сократить задержки».
- В главе 2:
  - блок «Данные и кэш»: PostgreSQL как основная база, реплики для чтения, Redis как кэш для «горячих» данных (ближайшие выгульщики, сессии), TTL, S3 для файлов;
  - блок «Чтение и запись»: «для чтений подключаем реплику базы и кэш Redis»;
  - блок «Масштабирование кэша и очередей»: Redis как кэш, кластер Redis для горизонтального масштабирования.

То есть:
- уже показано, что кэш существует и что он «ускоряет» и снимает нагрузку;
- упомянут Redis, TTL и масштабирование кэша;
- но почти нет:
  - формального определения и модели «что такое кэш и где он живёт в системе»;
  - терминов и паттернов (cache-aside, write-through, stampede и т.п.);
  - подробного разбора проблем (устаревшие данные, инвалидация, гонки, dogpile);
  - разговоров про многослойное кэширование, тегирование и версионирование.

Вывод: в нашей части не нужно объяснять кэш «с нуля для джунов», но стоит дать короткий, практический advanced‑рефреш, который логично продолжит главу 2 и подведёт к cache coherence.

---

## Блок 1. Модель кэша и базовые паттерны (общий ввод ко всей части)

Этот блок идёт в начале части 1 и «склеивает» подпункты A, B, C. Время: 5–7 минут.

### 1. Кэш как часть архитектуры, а не просто «ускоритель»
   - Что такое кэш в терминах архитектуры: «быстрый, ограниченный, потенциально устаревающий слой рядом с медленным, но источником истины».
   - Где он обычно стоит: перед базой, перед сторонним API, перед тяжёлой бизнес‑логикой.
   - Какие метрики и ограничения важны: latency, hit rate, пропускная способность, объём, TTL.

### 2. Слои кэширования в реальных системах
   - Браузерный кэш / HTTP‑кэш (ETag, Cache-Control).
     - Что может храниться:
       - статические ресурсы (JS, CSS, шрифты, картинки, иконки);
       - ответы API, если помечены подходящими заголовками;
       - offline‑ресурсы и данные в Cache Storage через Service Worker.
     - Как инвалидируется:
       - заголовки `Cache-Control` (`max-age`, `no-store`, `no-cache`, `must-revalidate`);
       - условные запросы с `ETag` / `If-None-Match`, `Last-Modified` / `If-Modified-Since`;
       - версионирование статических файлов (hash в имени: `app.[hash].js`) и cache busting;
       - обновление Service Worker’а и явная очистка/миграция Cache Storage.
   - CDN / edge‑кэширующие прокси.
   - Кэш на уровне приложения (in‑process) — LRU в памяти сервиса.
   - Распределённый кэш (Redis/Memcached‑кластер).
   - Кэш на стороне БД / индексные структуры / материализованные представления.
   - Где именно в нашем домене (самокаты/котовыгуливание/такси) эти слои появляются на схеме.

### 3. Зачем кэш реально используют (use‑cases)
   - Разгрузка других систем:
     - снижение нагрузки на основную БД (горячие ключи, тяжёлые JOIN/агрегации);
     - снижение количества обращений к внешним API.
   - Ускорение ответов для горячих чтений (карточка пользователя, список ближайших объектов, состояние заказа).
   - Переиспользование дорогих вычислений:
     - предрасчитанные отчёты, агрегации, подборки рекомендаций;
     - сохранение результатов тяжёлых алгоритмов матчинга.
   - Особые кейсы: rate limiting, feature‑флаги, флаги доступности ресурсов.

### 4. Основные проблемы кэширования
   - Устаревшие данные (stale reads) и рассинхронизация с источником.
   - Cache stampede/dogpile (thundering herd problem) — упомянуть как типичную проблему, без детального разбора (подробно в блоке 4).
   - Тёплый/холодный кэш, прогрев, ресет кластера кэша.
   - Ограниченный объём и эвикция: что и почему будет выбрасываться.
     - стратегии вытеснения: LRU, LFU, FIFO, TTL-only, random eviction;
     - как выбор стратегии связан с паттерном доступа (горячие ключи, хвост распределения).

### 5. Базовые паттерны взаимодействия с кэшем
   - Cache-aside (lazy loading) — самый частый кейс; как это выглядит в коде/на схеме.
   - Cache-ahead / pre-warming — когда мы заранее кладём данные в кэш, предвосхищая запросы (например, популярные маршруты/подборки).
   - Read-through / write-through / write-behind — чем отличаются, когда применимы.
   - 1–2 простые flow‑диаграммы «запрос → кэш → БД» без длинных списков.

### 6. Инвалидация и управление свежестью
   - TTL как тупой, но дешёвый инструмент; где этого достаточно, а где — нет.
   - Явная инвалидация по событиям: pub/sub, сообщения от БД (CDC), доменные события.
   - Частичные инвалидации (по ключу, по тегу, по «версии данных»).

### 7. Тегирование и версионирование кэша
   - Идея тегов: группировать связанные ключи (например, все данные пользователя) для массовой инвалидации.
   - Версионирование кэша: включение версии схемы/данных в ключ (или отдельное поле) для безопасных деплоев и миграций.
   - Как это помогает при изменении бизнес‑логики и схемы БД, не убивая сразу весь кластер кэша.

### 8. Мост к последующим подпунктам
   - Подводка: теперь у нас не один кэш, а пирамидка слоёв, в каждом из которых лежат копии одних и тех же данных.
   - Вопросы:
     - как сделать так, чтобы эти копии не противоречили друг другу (подводка к подпункту A — cache coherence);
     - как именно распределить данные по уровням кэша и что где держать (подводка к подпункту B — многоуровневое кэширование);
     - что делать, когда всё это ломается под нагрузкой (подводка к подпункту C — сложные проблемы кэширования).

---

## Блок 2 (A). Cache Coherence в распределённых системах

Ориентир: 10–15 минут, можно ужимать/расширять.

1. **Зачем вообще говорить про cache coherence в распределённых системах**
   - У нас не один кэш, а много: локальные кэши сервисов, общий Redis/Memcached, CDN, браузер и т.д.
   - Интуитивная проблема: «почему пользователю показывают старые данные, хотя запись в БД уже обновилась?».

2. **Определения: cache coherence vs consistency**
   - Cache coherence — про согласованность _копий одного и того же объекта_ между разными кэшами.
   - Отстроиться от «консистентности данных в БД» и от CAP-теоремы.
   - Условие: «нет двух кэшей с противоречащими значениями» + обсудить, насколько быстро мы этого требуем.

3. **Мысленная модель: аналогия с процессорными кэшами, но в более «грязном» мире**
   - В CPU есть протоколы MESI и жёсткий порядок операций.
   - В распределённой системе:
     - ненадёжная сеть,
     - непредсказуемые задержки,
     - нет глобальных часов.
   - Хочется ощущения «как будто данные в одном месте», но платим ростом сложности и latency.

4. **Типичные архитектуры кэшей и где там всплывает coherence**
   - Один общий распределённый кэш-кластер (Redis/Memcached) поверх БД: coherence проще, но есть TTL, репликация, шардирование.
   - Многоуровневый кэш:
     - L1 — локальный in-memory кэш в каждом сервисе;
     - L2 — общий Redis;
     - L3 — БД.
   - CDN / edge-кэши поверх API.
   - На каждом уровне — свой компромисс между свежестью, latency и сложностью.

5. **Механизмы обеспечения согласованности**
   - Здесь не вводим новые паттерны (они уже были в блоке 1), а показываем:
     - как выбор стратегии записи (cache-aside, read-/write-through, write-behind) влияет на согласованность между уровнями кэша и БД;
     - почему синхронные обновления/инвалидация дают более сильную когерентность, а асинхронные — повышают риск временного рассинхрона.
   - Инвалидация vs обновление:
     - связать с ранее рассказанными TTL и событийной инвалидацией (pub/sub, message bus, CDC);
     - объяснить, как задержки в этих механизмах превращаются в конкретные inconsistency‑кейсы.
   - Push vs pull:
     - кэш сам запрашивает обновления (pull) vs получает события извне (push) — как это влияет на задержку до «согласованного» состояния.

6. **Сложные кейсы и баги**
   - Одновременные запросы: гонки при записи, lost update, грязное чтение.
   - Split-brain и расхождение между узлами кэша.
     - отметить, что в блоке 4 будет живой инцидент со split-brain.
   - Примеры:
     - профиль пользователя;
     - баланс/лимиты;
     - корзина/остатки товара;
     - rate limiting.

7. **Trade-off’ы: цена сильной когерентности**
   - Сильная когерентность = больше синхронизации между узлами, выше latency и стоимость.
   - Где достаточно eventual coherence (лента, счётчики лайков).
   - Где нужна «почти» strong coherence (деньги, лимиты, инвентарь) и какие паттерны помогают:
     - версионирование (ETag, версии записей);
     - CAS/compare-and-set;
     - fencing tokens, лизинговые блокировки.

8. **Наблюдаемость и тестирование когерентности**
   - Метрики:
     - доля stale reads;
     - hit/miss каждого уровня кэша;
     - частота инвалидаций.
   - Chaos/latency injection: как проверить, что при задержках и падениях модель согласованности не разваливается.
   - Типичные вопросы на собеседовании:
     - какие гарантии по свежести данных в кэше вы даёте?
     - как убедиться, что кэш и БД не расходятся?

---

## Блок 3 (B). Многоуровневое кэширование и оптимизации

Ориентир: 10–15 минут.

1. **Многоуровневая схема кэширования в нашем домене**
   - Конкретная картинка: клиент → CDN/edge → API‑шлюз → backend‑сервисы (с L1‑кэшами) → Redis‑кластер → БД/хранилища.
   - Что на каком уровне держим: статика, результаты API, агрегаты, сессии, справочники и т.п.

2. **Чтения через несколько уровней кэша**
   - Типичный read‑flow: клиентский кэш → edge → L1 → L2 → БД.
   - Где хотим максимальный hit‑rate и почему (обычно L1+L2).
   - Как multi-level кэш влияет на tail latency: где выгодно положить ещё один слой, а где нет.

3. **Записи и обновления в многоуровневой системе**
   - Порядок обновления слоёв: сначала источник истины, потом инвалидация/обновление кэшей.
   - Выбор стратегии: «invalidate‑all» vs «invalidate‑by‑key/tag» vs «lazy refresh on next read».
   - Trade‑off’ы: чем больше уровней, тем сложнее поддерживать согласованность.

4. **Оптимизации под реальные паттерны трафика**
   - Горячие ключи (hot keys) и их обработка:
     - распределение нагрузки по нескольким шардам/репликам кэша;
     - запросы через отдельный слой/сервер для горячих данных.
   - Cache-ahead / pre-warming:
     - прогрев популярных маршрутов/точек/подборок перед пиком;
     - как не «убить» БД прогревом.
   - Request coalescing / single flight:
     - если 100 запросов одновременно прилетели к одному ключу — даём в БД сходить только одному.

5. **Эвикция и управление памятью на разных уровнях**
   - Почему разные уровни могут использовать разные стратегии:
     - LRU/LFU в in‑process кэше;
     - TTL + LRU в Redis;
     - короткий TTL на edge‑уровне.
   - Как читать и использовать статистику по эвикциям и hit‑rate (о чём спрашивают на собесе).

6. **Наблюдаемость и настройка**
   - Какие метрики нужны именно для multilevel:
     - hit‑rate по каждому слою;
     - количество invalidations/second;
     - распределение latency по слоям.
   - Как по метрикам принимать решения: где добавить/убрать уровень, где поменять TTL.

---

## Блок 4 (C). Сложные проблемы кэширования и практические кейсы

Ориентир: 10–15 минут. Здесь логично собрать «тёмную сторону» паттернов из блоков 1–3 и показать, как это обсуждать на собесе.

1. **Thundering herd / cache stampede**
   - Сценарий: ключ протух, десятки тысяч запросов одновременно лезут в БД.
   - Паттерны решения:
     - mutex/lock вокруг заполнения кэша (single flight);
     - «заглядывание вперёд» по TTL (early refresh);
     - jitter/randomized TTL, чтобы ключи не истекали одновременно.

2. **Управление устаревшими данными**
   - Где можно жить с сильно устаревшими данными (лента, счётчики) и почему.
   - Где нельзя (деньги, лимиты, баланс, инвентарь) и как тогда строим кэш:
     - короткие TTL + строгие проверки по БД;
     - хранение только вспомогательной информации в кэше;
     - использование версий/ETag’ов.

3. **Инциденты из продакшена (примерно 2–3 истории)**
   - Ошибка инвалидации: кэш показывает старую цену/баланс.
   - Неправильный TTL/эвикция → кэш постоянно холодный, система тормозит.
   - Split-brain в кластере кэша → разные ответы для разных пользователей (связать с обсуждением из блока 2).
   - Для каждой истории:
     - как выглядели симптомы;
     - что оказалось root cause;
     - какие изменения в архитектуре/паттернах помогли.

4. **Кэш и собеседования по system design**
   - Типовые вопросы:
     - «Как будете использовать кэш, чтобы выдержать X rps?»;
     - «Что будете кэшировать первым делом, а что точно не будете?»;
     - «Как убедитесь, что кэш и БД не расходятся на критичных данных?».
   - На что обычно смотрят интервьюеры:
     - понимаете ли вы trade‑off’ы между свежестью и производительностью;
     - умеете ли объяснять стратегию инвалидации и поведение при сбоях;
     - упоминаете ли thundering herd, hot keys, observability.

---

## Ссылки на материалы

Подборка для углубления, чтобы оттуда вытаскивать идеи, примеры и формулировки.

### Русскоязычные источники

- **Когерентность кэша — Википедия**  
  Базовые определения и терминология.  
  https://ru.wikipedia.org/wiki/Когерентность_кэша

- **«Мифы о кэше процессора, в которые верят программисты» (Habr)**  
  Хорошее интуитивное объяснение когерентности кэша на уровне процессора, можно брать метафоры и объяснения.  
  https://habr.com/ru/articles/354748/

- **«Проектирование эффективной системы кэширования» (Habr)**  
  Обзор видов кэша, многоуровневого кэширования и distributed cache; хороший фон для твоей «продвинутой» части.  
  https://habr.com/ru/articles/853340/

- **«Что, если выкинуть все лишнее из базы в распределенный кэш» (ЮMoney + Hazelcast)**  
  Реальный кейс с распределённым кэшем, split-brain, согласованностью и проблемами под высокой нагрузкой.  
  https://habr.com/ru/companies/yoomoney/articles/332462/

- **«Как распилить монолит на сервисы и сохранить целостность данных» (T‑Банк)**  
  Про микросервисы, целостность данных и роль распределённого кэша в этом всём.  
  https://habr.com/ru/companies/tbank/articles/474994/

(Дополнительно можно поискать на YouTube по запросам «кэширование распределённые системы», «cache invalidation системный дизайн» — там есть доклады от Тинькофф, Avito, Яндекс, Ozon.)

### Англоязычные источники — распределённый кэш и согласованность

- **Meta Engineering — «Cache made consistent»**  
  История о том, как Facebook/Meta обеспечивали согласованность большого распределённого кэша.  
  https://engineering.fb.com/2022/06/08/core-infra/cache-made-consistent/

- **«Distributed Caching Woes: Cache Invalidation» (Medium)**  
  Разбор боли с cache invalidation в распределённой системе и типовых паттернов.  
  https://medium.com/systems-architectures/distributed-caching-woes-cache-invalidation-c3d389198af3

- **ByteByteGo — «Distributed Caching: The Secret to High-Performance Systems»**  
  Обзор distributed cache, паттернов кэширования и проблем согласованности/инвалидации.  
  https://blog.bytebytego.com/p/distributed-caching-the-secret-to

- **Distributed cache — Wikipedia**  
  Общее представление о distributed cache, упоминание coherence, cache stampede и т.п.  
  https://en.wikipedia.org/wiki/Distributed_cache

- **Паттерны кэширования в Redis**  
  Официальные или околоредисные материалы по cache-aside, write-through, write-behind, read-through.  
  (Поиск: “Redis caching patterns” — актуальный раздел документации Redis.)

### Видео

- **«Effective Caching Strategies for Distributed Systems» (YouTube)**  
  Доклад про стратегии кэширования в распределённых системах, проблемы согласованности.  
  https://www.youtube.com/watch?v=vaUozFw-Y9k

- **«How Do You Achieve Cache Coherence In Distributed Systems» (YouTube)**  
  Короткое видео именно про cache coherence в распределённом контексте.  
  https://www.youtube.com/watch?v=L4OyfmIy-xU

---

Дальше по этому файлу можно:
- уточнять/расширять план (добавлять конкретные примеры и истории);
- помечать, какие ссылки реально использованы в сценарии;
- набрасывать варианты формулировок для сценария, которые потом переписываются под твой голос.
