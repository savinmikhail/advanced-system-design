## Файл 3: `04-2-throughput-scaling.md`

### Заголовок

**Часть 4.2. Throughput Scaling: почему “добавим серверов” не работает**

---

### Цель видео

* Показать, почему throughput растёт не линейно с количеством серверов.
* Разобрать Amdahl, Gustafson и интуицию Universal Scalability Law.
* Показать, как contention и coherence убивают масштабирование.
* Показать практические примеры: БД, Redis, PHP-FPM, очереди.
* Дать базовые приёмы: backpressure, разделение нагрузок, разгрузка shared ресурсов.

---

### План видео (high level)

1. Напоминание про связь latency/throughput/Little.
2. “Добьём” интуицию: рост нагрузки → рост concurrency → рост latency.
3. Amdahl’s Law: непараллелящаяся часть.
4. Gustafson: масштабируем задачу, а не ускоряем одну и ту же.
5. Contention и coherence: shared ресурсы, lock’и, hot keys, кластеры БД.
6. Примеры из практики: БД, Redis, PHP-FPM.
7. Приёмы:

    * backpressure;
    * queue-based load leveling;
    * разделение нагрузок и данных;
    * изоляция hot ресурсов.
8. Вывод: что именно надо делать, чтобы throughput рос устойчиво.

---

### Сценарий

#### 1. Напоминание базовой формулы (0:00–3:00)

Напоминаем:

> **Latency = Concurrency / Throughput**

При фиксированном throughput:

* рост входящего RPS → растёт concurrency → растёт latency.

Если мы хотим удержать latency на приемлемом уровне при росте нагрузки, нужно:

* либо **повышать throughput**;
* либо **ограничивать concurrency** (backpressure, очереди, быстрые отказы);
* либо и то, и другое.

Наивная идея: “давайте просто добавим серверов”.
Сейчас посмотрим, почему эта идея работает только до определённого момента.

---

#### 2. Amdahl’s Law: непараллелящаяся часть (3:00–8:00)

**Закон Амдаля** говорит:

> Ускорение системы ограничено долей, которую можно распараллелить.

Очень упрощённый пример:

* 70% времени запрос проводит в параллелящейся части (можно распределить по серверам);
* 30% — в последовательной части (один ресурс, один поток, один lock).

Если бы у нас был “идеальный” параллелизм:

* 70% времени можно было бы сделать “мгновенным”;
* но 30% останутся.

Тогда **максимальное теоретическое ускорение**:

```text
S_max = 1 / (1 - p)
где p = доля параллелящейся части
```

При p = 0.7:

```text
S_max = 1 / 0.3 ≈ 3.33
```

Что это значит по-человечески:

* хоть 100 серверов поставь,
  если 30% запроса упираются в один последовательный кусок —
  ты никогда не ускоришь систему больше чем в 3.3 раза.

Примеры “непараллелящейся части”:

* один монолитный сервис аутентификации;
* одна очередь, которую читает ограниченное число воркеров;
* один мастер в БД, через который идут все записи.

---

#### 3. Gustafson: масштабируем задачу (8:00–11:00)

**Закон Густафсона** смотрит на ситуацию по-другому:

> Вместо “как ускорить одну и ту же задачу” смотрим на
> “как растёт объём работы, когда у нас больше ресурсов”.

Инженерная интерпретация:

* часто нам не нужно делать те же 1000 запросов быстрее;
* нам нужно переваривать **уже 100 000 запросов**;
* и мы готовы чуть пожертвовать latency ради общих объёмов.

Густафсон говорит:

* при росте числа узлов мы увеличиваем **объём параллелящейся работы**;
* но **последовательная часть всё равно ограничивает** масштабирование.

То есть в продакшене важно:

* не только добавить машины;
* но и **уменьшить долю последовательной, “shared” части**.

---

#### 4. Contention и coherence: где умирает масштабирование (11:00–18:00)

Два главных убийцы throughput:

1. **Contention** — мы спорим за общий ресурс.
2. **Coherence** — мы тратим время на согласование состояния между копиями.

Примеры contention:

* Один hot ключ в Redis, по которому у нас инкремент счётчика.
* Один row-lock в БД, через который проходят все обновления.
* Глобальный мьютекс в приложении.

Примеры coherence:

* Репликации БД, где нужно поддерживать согласованное состояние.
* Кластеры кэшей, где надо инвалидировать/обновлять значения на нескольких нодах.
* Распределённые транзакции между сервисами.

Интуиция:

* чем больше узлов, тем больше трафик между ними;
* чем больше shared состояний, тем дороже становится его поддерживать;
* в какой-то момент добавление нового сервера **увеличивает внутреннюю координацию больше, чем даёт полезного throughput**.

---

#### 5. Практические примеры (18:00–26:00)

**База данных**

* В начале: одна БД, один сервер, всё летает.
* Потом: добавляем реплики для чтения — кажется, throughput растёт.
* Но:

    * записи всё равно упираются в один мастер;
    * сильная консистентность / транзакции / блокировки не дают распараллелить всё.

В итоге:

* рост нагрузок приводит к росту contention на lock’ах и индексации;
* репликация добавляет задержку;
* в какой-то момент throughput перестаёт расти, а latency начинает ухудшаться.

**Redis и hot keys**

* Мы добавляем ноды в кластер Redis.
* Вроде бы распределяем ключи по shard’ам.
* Но если один ключ “горячий” (например, глобальный счётчик) — все запросы к нему идут на одну ноду.

Результат:

* одна нода перегружена;
* throughput всей системы ограничен её возможностями;
* добавление ещё 10 нод ничего не меняет, пока мы не переработали схему данных.

**PHP-FPM и pool’ы**

* В конфиге FPM есть количество воркеров.
* При low load всё хорошо: каждый воркер обрабатывает запрос, latency стабильная.
* При росте нагрузки:

    * мы упираемся в max_children;
    * новые запросы начинают стоять в очереди;
    * latency растёт, даже если CPU ещё не 100%.

Добавляем сервера:

* да, какое-то время throughput растёт;
* но:

    * если БД не масштабируется — упираемся в неё;
    * если Redis не тянет — упираемся в него;
    * если сеть между PHP и БД перегружена — упираемся в сеть.

---

#### 6. Базовые приёмы для устойчивого роста throughput (26:00–35:00)

**Backpressure**

Идея:

> Система должна **честно сказать “я не вывожу”**,
> а не молча накапливать вечные очереди.

Механики:

* лимитируем количество параллельных запросов к БД / Redis / внешним API;
* при превышении лимита:

    * быстро отдаём 429 / 503;
    * или сбрасываем сообщение в “мертвую” очередь;
    * или просим клиента ретраить позже с экспоненциальной задержкой.

Выигрыш:

* мы **контролируем concurrency**, а значит и latency;
* защищаем shared ресурсы от коллапса.

**Queue-based load leveling**

Вместо того чтобы обрабатывать все запросы сразу:

* складываем задачи в очередь;
* обрабатываем с постоянной скоростью воркеров.

Плюсы:

* сглаживаем пики нагрузки;
* отделяем приём запросов от их обработки;
* можем независимо масштабировать фронт и воркеров.

Минусы:

* появляется дополнительная задержка (latency);
* нужно аккуратно выбирать глубину очереди и политику обработки.

**Разделение нагрузок и данных**

Чтобы уменьшить contention:

* разбиваем монолитные ресурсы:

    * шардируем БД по пользователям / регионам;
    * разделяем сервисы по доменам;
    * выносим отдельные кластеры под тяжёлые операции.
* переводим горячие операции в отдельные потоки обработки:

    * отдельные кластеры Redis для разных типов данных;
    * отдельные очереди и воркеры под тяжёлые задачи.

Идея:

* вместо одного куска “последовательной части” делаем несколько независимых;
* уменьшаем долю непараллелящейся работы → выигрываем по Амдалю.

**Изоляция hot ресурсов**

Если видим hot key / hot таблицу / hot endpoint:

* выносим его в отдельный сервис / кластер;
* даём ему собственные лимиты, свой backpressure, свои воркеры.

Это позволяет:

* не давать одному горячему кейсу “съесть” весь throughput;
* масштабировать именно то место, где действительно больно.

---
