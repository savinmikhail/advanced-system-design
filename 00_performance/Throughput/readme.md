### Часть 4.2. Throughput Scaling: почему “добавим серверов” не работает

#### 1. Напоминание базовой формулы (0:00–3:00)

Напоминаем:

> **Latency = Concurrency / Throughput**

При фиксированном throughput:

* рост входящего RPS → растёт concurrency → растёт latency.

Если мы хотим удержать latency на приемлемом уровне при росте нагрузки, нужно:

* либо **повышать throughput**;
* либо **ограничивать concurrency** (backpressure, очереди, быстрые отказы);
* либо и то, и другое.

Наивная идея: “давайте просто добавим серверов”.
Сейчас посмотрим, почему эта идея работает только до определённого момента.

---

#### 2. Amdahl’s Law: непараллелящаяся часть (3:00–8:00)

**Закон Амдаля** говорит:

> Ускорение системы ограничено долей, которую можно распараллелить.

Очень упрощённый пример:

* 70% времени запрос проводит в параллелящейся части (можно распределить по серверам);
* 30% — в последовательной части (один ресурс, один поток, один lock).

Если бы у нас был “идеальный” параллелизм:

* 70% времени можно было бы сделать “мгновенным”;
* но 30% останутся.

Тогда **максимальное теоретическое ускорение**:

```text
S_max = 1 / (1 - p)
где p = доля параллелящейся части
```

При p = 0.7:

```text
S_max = 1 / 0.3 ≈ 3.33
```

Что это значит по-человечески:

* хоть 100 серверов поставь,
  если 30% запроса упираются в один последовательный кусок —
  ты никогда не ускоришь систему больше чем в 3.3 раза.

Это та же интуиция, что и в фразе:  
**«девять женщин за месяц не родят одного ребёнка»**.  
Есть часть работы, которая по определению последовательная: её нельзя разрезать на кусочки и раздать параллельно.

Примеры “непараллелящейся части”:

* один монолитный сервис аутентификации;
* одна очередь, которую читает ограниченное число воркеров;
* один мастер в БД, через который идут все записи.

---

#### 3. Gustafson: масштабируем задачу (8:00–11:00)

С Амдалем мы смотрели на мир так:

> Есть **одна и та же задача**.
> Мы добавляем ресурсы и спрашиваем: “насколько быстрее она станет выполняться?”

И быстро упёрлись в последовательную часть: есть кусок работы, который по природе нельзя распараллелить, и он ставит потолок ускорению.

**Закон Густафсона** предлагает другой взгляд:

> Зафиксируем **бюджет времени** и спросим:
> “сколько **работы** мы можем сделать за это время, если добавим ресурсов?”

То есть:

* Амдаль: “как сделать одну задачу не за 3 секунды, а за 0.5?”
* Густафсон: “раз уж нам норм жить с 3 секундами —
  давай за эти 3 секунды делать **больше полезной работы**”.

Инженерная интерпретация:

* нам не всегда нужно делать те же 1000 запросов быстрее;
* чаще нам нужно переваривать **уже 100 000 запросов** за те же 200 ms p95;
* или считать **более тяжёлые отчёты** за то же время.

Формально ускорение по Густафсону при N узлах можно записать так:

```text
S(N) = N - α · (N - 1)
```

где `α` — доля **непараллелящейся** части работы.

Пример:

* пусть последовательная часть = 10% (`α = 0.1`);
* ставим `N = 8` узлов:

```text
S(8) = 8 - 0.1 · (8 - 1)
     = 8 - 0.7
     = 7.3
```

То есть за то же время мы можем сделать работы примерно в **7.3 раза больше**, чем на одном узле
(но всё равно не 8 раз, потому что 10% остаются последовательными).

С практической точки зрения это означает:

* масштабируя кластер, мы в реальности используем новые ресурсы, чтобы:

  * обрабатывать **больше трафика** при том же p95;
  * считать **более тяжёлые отчёты** за то же время;
* но доля последовательной, shared-части (`α`) всё равно ограничивает, насколько близко мы подберёмся к идеальному `S(N) ≈ N`.

#### 3.5. Universal Scalability Law: почему кривая выгибается вниз

Амдаль и Густафсон говорят нам, **какая теоретическая польза** от добавления ресурсов:
* Амдаль — про потолок ускорения;
* Густафсон — про то, как впихнуть больше работы в тот же бюджет времени.

Но в реальном продакшене есть ещё одна гадость:  
по мере роста числа узлов мы начинаем платить:

* за **contention** — конкуренцию за общие ресурсы;
* за **coherence** — согласование состояния между репликами.


Примеры contention:

* Один hot ключ в Redis, по которому у нас инкремент счётчика.
* Один row-lock в БД, через который проходят все обновления.
* Глобальный мьютекс в приложении.

Примеры coherence:

* Репликации БД, где нужно поддерживать согласованное состояние.
* Кластеры кэшей, где надо инвалидировать/обновлять значения на нескольких нодах.
* Распределённые транзакции между сервисами.


Это описывает **Universal Scalability Law** (закон универсальной масштабируемости):

```text
S(N) = N / (1 + σ · (N - 1) + κ · N · (N - 1))
````

где:

* `N` — число узлов,
* `σ` — накладные расходы на contention,
* `κ` — накладные расходы на coherence.

Интуитивно:

* при маленьком N знаменатель почти 1 → S(N) ≈ N, масштабирование почти линейное;
* дальше σ · (N - 1) начинает доминировать — рост замедляется, кривая выходит на плато;
* при большом N κ · N · (N - 1) становится огромным —
  **затраты на согласование и координацию растут быстрее, чем полезный throughput**,
  и кривая реально начинает клониться вниз.

Вот отсюда и рождается реальный эффект “добавим ещё серверов — стало только хуже”:
мы увеличили количество узлов, но ещё сильнее увеличили внутреннюю координацию и борьбу за shared-ресурсы.

![img.png](img.png)

Пример:

**База данных**

* В начале: одна БД, один сервер, всё летает.
* Потом: добавляем реплики для чтения — кажется, throughput растёт.
* Но:

    * записи всё равно упираются в один мастер;
    * сильная консистентность / транзакции / блокировки не дают распараллелить всё.

В итоге:

* рост нагрузок приводит к росту contention на lock’ах и индексации;
* репликация добавляет задержку;
* в какой-то момент throughput перестаёт расти, а latency начинает ухудшаться.

---

#### 6. Базовые приёмы для устойчивого роста throughput (26:00–35:00)

##### **Backpressure**

Идея:

> Система должна **честно сказать “я не вывожу”**,
> а не молча накапливать вечные очереди.

Механики:

* лимитируем количество параллельных запросов к БД / Redis / внешним API;
* при превышении лимита:

    * быстро отдаём 429 / 503;
    * или сбрасываем сообщение в “мертвую” очередь;
    * или просим клиента ретраить позже с экспоненциальной задержкой.

Выигрыш:

* мы **контролируем concurrency**, а значит и latency;
* защищаем shared ресурсы от коллапса.

##### **Queue-based load leveling**

Вместо того чтобы обрабатывать все запросы сразу:

* складываем задачи в очередь;
* обрабатываем с постоянной скоростью воркеров.

Плюсы:

* сглаживаем пики нагрузки;
* отделяем приём запросов от их обработки;
* можем независимо масштабировать фронт и воркеров.

Минусы:

* появляется дополнительная задержка (latency);
* нужно аккуратно выбирать глубину очереди и политику обработки.

##### **Разделение нагрузок и данных**

Чтобы уменьшить contention:

* разбиваем монолитные ресурсы:

    * шардируем БД по пользователям / регионам;
    * разделяем сервисы по доменам;
    * выносим отдельные кластеры под тяжёлые операции.
* переводим горячие операции в отдельные потоки обработки:

    * отдельные кластеры Redis для разных типов данных;
    * отдельные очереди и воркеры под тяжёлые задачи.

Идея:

* вместо одного куска “последовательной части” делаем несколько независимых;
* уменьшаем долю непараллелящейся работы → выигрываем по Амдалю.

##### **Изоляция hot ресурсов**

Если видим hot key / hot таблицу / hot endpoint:

* выносим его в отдельный сервис / кластер;
* даём ему собственные лимиты, свой backpressure, свои воркеры.

Это позволяет:

* не давать одному горячему кейсу “съесть” весь throughput;
* масштабировать именно то место, где действительно больно.

___

> Производительность распределённой системы — это не настройка одного Nginx,
> а баланс между математикой (Little, Amdahl), архитектурой (shared ресурсы, шардирование)
> и эксплуатацией (ретраи, очереди, алерты, circuit breakers).
