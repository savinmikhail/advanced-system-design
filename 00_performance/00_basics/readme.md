## Часть 1. Производительность: базовая механика (latency, throughput, хвосты, Little)

### 1. Зачем вообще говорить про производительность

> Представьте, что вы открыли приложение, нажали на кнопку — и оно думает.  
> Один раз — ладно.  
> Второй — раздражает.  
> На третий вы закрываете приложение и идёте к конкуренту.

Разработчики в этот момент любят говорить:
“Средняя задержка у нас 200 ms, всё отлично”.

Проблема в том, что пользователю на среднее плевать.  
Пользователю важно **его конкретное действие** — уложилось оно в комфортные 200 ms
или застряло в редком хвосте на 3 секунды.

Отсюда связка: **frustration → деньги**.  
Задержка → раздражение → брошенные корзины → меньше выручка.

Чтобы этим управлять, надо договориться о двух базовых величинах: **latency** и **throughput**.

### 2. Что такое Latency и Throughput

**Latency** — это **время ответа**: сколько проходит от момента, когда запрос попал в систему, до момента, когда мы отдали результат.

Примеры:

* HTTP-запрос к API: от получения запроса веб-сервером до отправки HTTP-ответа.
* Запрос к базе: от отправки SQL до получения первой строки результата.
* Сообщение в очереди: от записи в очередь до обработки воркером.

**Throughput** — это **скорость обработки**, сколько таких запросов мы реально перевариваем в единицу времени.

Типичные формулировки в живом разговоре:

* “Nginx держит ~5000 запросов в секунду на чтение статики”.
* “Эта очередь стабильно переваривает 20 000 сообщений/сек”.
* “База нормально живёт на 2000 транзакций/сек на запись, дальше уже больно”.

### 3. Связь между ними: закон Литтла

Дальше нам пригодится один очень простой закон теории очередей — **закон Литтла**.

> **Latency = Concurrency / Throughput**

Где:

* **Concurrency** — сколько запросов одновременно “висят” в системе;
* **Throughput** — сколько запросов в секунду мы реально завершаем;
* **Latency** — среднее время, которое один запрос проводит внутри.

К примеру:

* в системе одновременно “в пути” **3000** запросов;
* реальный throughput — **1000 RPS**.

Тогда:

```text
Latency = Concurrency / Throughput
Latency = 3000 / 1000 = 3 секунды
````

То есть:

* при 1000 RPS 3000 параллельных запросов ⇒ **3 секунды ожидания**;
* если concurrency вырастет до 6000 при том же throughput ⇒ **6 секунд**.

Зачем нам это в реальной жизни, а не только в теории:

* Вы смотрите на график: “в очереди висит 10 000 запросов, throughput 2000 RPS” → по формуле сразу видите, что **средняя задержка уже секунды**, не миллисекунды.
* Понимаете, что **пока вы не увеличите throughput**, все попытки “покрутить таймауты”, “уменьшить ретраи” и “оптимизировать код” мало что дадут — очередь всё равно будет копиться.
* На собесах по системдизайну от вас часто ждут именно такого рассуждения:
  не “давайте добавим серверов”, а “при таком RPS и таком concurrency latency по Литтлу будет вот столько, значит нужно либо уменьшать количество одновременно висящих запросов, либо повышать throughput”.

Если совсем коротко:

> Как только **очередь растёт**, **время ответа растёт**.
> Закон Литтла просто даёт вам формулу, чтобы это считать, а не ощущать “на глаз”.

---

### 4. Почему среднее время ответа — плохой ориентир

Допустим, у нас есть 100 запросов:

* 90 обрабатываются за 100 ms;
* 10 — за 5 секунд.

Среднее время ответа:

```text
(90 * 0.1 + 10 * 5) / 100
= (9 + 50) / 100
= 0.59 секунды
```

“В среднем” у вас **590 ms**.
На отчёте выглядит терпимо.

По факту:

* 90 человек получают быстрый ответ и думают “нормально работает”;
* 10 человек сидят по **5 секунд** и считают ваш сервис мусором.

Бизнесу и пользователям важны не абстрактные 590 ms,
а:

* **какая доля** людей попадает в плохой опыт;
* **насколько плох** этот опыт по времени.

Для этого вводят **перцентили**.

### 5. Перцентили и хвост (tail latency)

Перцентиль — это “время, быстрее которого обслуживается X% запросов”.

Примеры:

* **p50** — половина запросов быстрее этого времени (по сути медиана).
* **p95** — 95% запросов быстрее этого времени.
* **p99** — 99% запросов быстрее.

Представим что для нашего прода метрики следующие:

* p50 = 150 ms,
* p95 = 400 ms,
* p99 = 2 s.

Что мы из этого читаем:

* половина запросов улетает за 150 ms — всё приятно;
* ещё 45% укладываются до 400 ms — уже не вау, но терпимо;
* **последний 1%** сидит до 2 секунд — и именно эти ребята потом пишут в отзывы “ничего не работает”.

Хвост распределения — это как раз этот небольшой процент очень медленных запросов.
**Tail latency** — это любые метрики, которые смотрят именно на хвост: p95, p99, p999.

На собесах и в реальной жизни разговор про “производительность” почти всегда должен быть в терминах p95/p99, а не “среднее у нас норм”.

### 6. Почему в распределённых системах хвост удлиняется

В монолите один HTTP-запрос часто выглядит просто:

* веб-сервер,
* один поход в базу,
* немного логики,
* ответ.

В распределённой системе цепочка превращается в:

* API-шлюз;
* сервис A;
* сервис B;
* очередь;
* сервис C;
* один-два похода в БД;
* кэш;
* иногда ещё внешнее API.

Теперь представим, что у **каждого** звена:

* p50 = 50 ms,
* p99 = 200 ms.

Типичный запрос, который проходит по 8–10 звеньям, в среднем всё равно будет быстрым.
Но **вероятность**, что хотя бы одно звено из цепочки попадёт в свой p99, уже совсем другая.

Грубо:

* одно звено иногда тормозит — ну ладно;
* десяток звеньев с ретраями и сетевыми задержками
  → ваш общий p99 легко вылезает в секунды, даже если отдельно каждый сервис “нормальный”.

Это и есть причина, почему в распределённых системах бороться приходится не только за “быстрый средний ответ”,
но и за **укрощение хвоста**: ограничивать fan-out, убирать лишние ретраи, ставить таймауты, делать кеширование и деградацию.

Дальше в главе мы как раз и будем разбирать:

* как уменьшать этот хвост и не дать ему убить систему;
* почему простой совет “давайте добавим серверов” не всегда спасает throughput и где нас упирают фундаментальные ограничения.
