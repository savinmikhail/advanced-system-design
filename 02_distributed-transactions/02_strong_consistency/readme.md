### Блок 3.3. Strong Consistency в распределённых системах (12–15 минут)

## Вступление: когда “рано или поздно” — это провал

В предыдущих частях мы честно смирились с тем, что большая часть систем живёт на **eventual consistency**:
саги, outbox, асинхронные индексы, кеши с TTL — данные разъезжаются по времени, но в итоге сходятся.

Для лент, профилей, рекомендаций, поиска, аналитики это нормально:
пользователь почти не страдает от небольшого лага.

Но есть узкий класс задач, где “рано или поздно” — это уже **ошибка**:

* баланс счёта не может “потом как‑нибудь сойтись”;
* один и тот же билет нельзя продать двум людям “на пару секунд”;
* права доступа не могут быть “в процессе обновления” в разных системах.

Здесь нам нужна **strong consistency** —
готовность платить latency, сложностью и деньгами за то,
чтобы после успешной записи **любое** чтение этого ключа видело одно и то же значение, независимо от узла.

## 1. Что такое Strong Consistency

Интуитивно strong consistency — это такое свойство системы:

> Если запись успешно завершилась,
> то любое последующее чтение **этого же ключа**
> увидит новое значение.
> Независимо от того, на какой узел попал запрос.

То есть:

* нет ситуации “записали 1000, а кто-то всё ещё видит 900”;
* нет игры “в каком регионе сейчас более свежие данные”;
* нет “реплика ещё не догнала”.

Это поведение, к которому мы привыкли в монолите с одной базой:

* сделали `UPDATE balance SET value = 1000 WHERE id = 1;`
* сразу же `SELECT value FROM balance WHERE id = 1;`
* всегда получаем 1000, если `UPDATE` закоммитился.

Проблема в том, что в распределённой системе это свойство приходится **выбивать зубами** — через протоколы согласования, синхронные репликации и рост latency.

---

## 2. Формально: linearizability

Если хочется формально, strong consistency почти всегда обсуждают в терминах **linearizability**.

Суть:

> Все операции над данным объектом выглядят так,
> как будто они происходят **в одном общем порядке во времени**,
> и каждая операция “врезана” в этот порядок как атомарная точка.

То есть:

* есть некоторое тотальное упорядочивание операций;
* каждая операция “случается” в какой-то момент времени между вызовом и ответом;
* все клиенты видят историю в согласованном виде — без “откатов назад” и “альтернативных веток”.

Пример с балансом:

* если где-то закоммитили `balance = 1000`,
* ни один клиент уже не увидит 900,
* и никто не увидит “1000, потом 900” без отдельной явной операции, которая вернула 900.

Linearizability — одна из самых строгих и дорогих по стоимости гарантий, которые вообще применяют в распределённых системах.

---

## 3. Почему strong consistency — это боль, а не просто “галочка в конфиге”

Чтобы дать strong consistency, система вынуждена делать вещи, которые распределённым системам в принципе не нравятся:

* **Синхронно согласовывать записи** между несколькими узлами/репликами.
* **Ждать подтверждений** от других нод перед тем, как сказать клиенту “OK”.
* **Координировать порядок операций**:

    * через протоколы согласования (Raft, Paxos и т.п.);
    * через глобальный лидер/сериализатор.
* Учитывать сетевые лаги, таймауты, частичные падения.

В результате:

* каждая запись — это не просто “вставь в локальную БД”, а маленький распределённый протокол;
* **latency записи растёт**;
* **tail latency** (p95/p99) становится сильно хуже;
* **throughput по записи** масштабируется гораздо хуже, чем “просто накидаем нод”;
* при сетевых проблемах strong consistency часто выигрывается ценой **потери доступности**: лучше отказать, чем ответить “старым” состоянием.

То есть strong consistency — это всегда обмен:

* меньше аномалий и рассинхронов,
* но дороже по скорости, отказоустойчивости и сложности.

---

## 4. Где strong consistency действительно критична

Не везде эта боль оправдана. Но есть области, где без этого нельзя.

Примеры:

* **Жёсткие финансовые транзакции**:

    * списание/зачисление денег;
    * учёт остатков на счетах;
    * взаиморасчёты между организациями.
* **Инвентаризация, где ошибка = прямые потери**:

    * количество товара на складе;
    * бронирование ограниченного ресурса.
* **Security и права доступа**:

    * ACL, роли, критичные пермишены;
    * смена пароля, блокировка аккаунта.
* **Операции без вменяемой компенсации**:

    * юридически значимые изменения;
    * транзакции, которые нельзя “откатить событиями”.
* **Сильные инварианты в реальном времени**:

    * “баланс не может уйти в минус”;
    * “один билет не может быть продан двум людям”.

Там ошибка в согласованности стоит дороже, чем все потери по производительности.

Всё остальное — профили, ленты, лайки, рекомендации, каталоги, аналитика — прекрасно живёт на eventual consistency.

---

## 5. Практические способы достигать strong consistency

Теперь — не про философию, а про конкретные архитектурные подходы.

### 5.1. Один лидер (primary–replica)

Классическая схема:

* есть **одна нода-лидер**, которая принимает все записи;
* остальные — только чтения (синхронно или асинхронно реплицируются).

Если репликация синхронная:

* запись считается успешной только после того, как лидер и реплики подтвердили её;
* чтения с реплик могут быть строго консистентными относительно лидера.

Плюсы:

* простая модель;
* понятно, где “истина” — на лидере;
* много СУБД так уже из коробки умеют.

Минусы:

* весь write-throughput упирается в один лидер;
* failover лидера = пауза и дополнительная сложность;
* при синхронной репликации latency записи растёт из-за ожидания всех.

Часто в реальных системах делают микс:

* критические операции читают с лидера (strong),
* остальные — с реплик (почти-strong или eventual).

---

### 5.2. Синхронная репликация и кворумы (quorum / majority)

Более общий подход — использовать **кворумы**:

* при записи требуем подтверждение от большинства (quorum write);
* при чтении — тоже от большинства (quorum read).

Пока **меньшинство** узлов отваливается/отстаёт, система остаётся консистентной.

Плюсы:

* можно переживать падение отдельных нод;
* linearizable-режим возможен (при правильной конфигурации read/write кворумов).

Минусы:

* запись = несколько сетевых вызовов перед ack;
* один медленный участник растягивает хвост;
* всё равно платим latency за синхронизацию.

---

### 5.3. Distributed lock managers и координация

Когда нужно сериализовать операции над каким-то ресурсом, используют:

* ZooKeeper;
* etcd;
* Google Chubby и аналогичные вещи.

Идея:

* операции над “важным объектом” идут через **глобальный lock/lease**;
* только тот, у кого lock, может делать изменения.

Плюсы:

* можно гарантировать отсутствие гонок на уровне кластера;
* удобно для лидера выбора, распределённых очередей, координаторов.

Минусы:

* все записи, требующие lock, проходят через один узкий координатор;
* ещё один сетевой хоп;
* падение/деградация lock-сервиса бьёт по всему, что на нём висит.

То есть strong consistency через глобальные блокировки работает, но по цене ещё одной критической подсистемы.

---

### 5.4. TrueTime и Google Spanner

Отдельная лига — Spanner-подобные системы.

Spanner делает очень сильную гарантию:

* распределённые транзакции **между датацентрами** выглядят как одна глобальная strongly-consistent база;
* использует **TrueTime** — API, которое даёт не просто “время”, а интервалы с оценкой погрешности (bound clock skew);
* протокол транзакций опирается на гарантированную верхнюю границу рассинхрона часов.

Результат:

* можно делать SQL-транзакции между регионами;
* и при этом утверждать, что они linearizable.

Цена:

* атомные часы, GPS, сложная физическая инфраструктура;
* затраты, которые оправданы далеко не в каждом бизнесе;
* фактически привязка к конкретному облаку и его экосистеме.

Если приземлить это на сценарии:

* **Банковский ledger между регионами.**

    * Хотим, чтобы баланс по счёту был точным в любой момент, независимо от того, в каком регионе выполняется операция.
    * Готовы платить десятками миллисекунд дополнительной latency и сложной инфраструктурой, потому что ошибка в балансе стоит дороже.
    * Здесь Spanner‑подобный подход (глобальные транзакции, TrueTime) может быть оправдан.

* **Обычный e-commerce с каталогом, поиском и аналитикой.**

    * Большая часть запросов спокойно живёт на eventual consistency;
    * ради пары полей “сильного ядра” (платёж, остаток на складе) проще локализовать strong consistency в одном регионе/хранилище,
      чем тащить за собой Spanner‑уровень инфраструктуры.

Полезно знать, что Spanner‑подобные системы вообще существуют и дают глобальную strong consistency,
но это точно не “паттерн на выходные”, а осознанный выбор для очень дорогих доменов.

---

## 6. Почему strong consistency нельзя “просто включить”

Сводим trade-off в более явный список.

1. **Latency растёт.**
   Любая запись — это координация нескольких узлов, иногда нескольких регионов.

2. **Tail latency взлетает.**
   P95/P99 определяется самой медленной нодой или самым медленным линком.

3. **Availability падает.**
   При сетевом разделении или падении части узлов система часто должна **отказывать**,
   чтобы не нарушить консистентность.

4. **Throughput по записи ограничен.**
   Глобальный порядок и синхронные протоколы плохо масштабируются “просто добавлением машин”.

5. **Сложность инфраструктуры растёт.**
   Нужны протоколы консенсуса, health-checkи, сложный failover, продуманная деградация.

Strong consistency — это не флажок в настройках, а целый архитектурный режим.

---

## 7. Когда strong consistency не нужна и будет только мешать

Самое полезное упражнение — честно вычеркнуть области, где она **не обязательна**.

На практике 90–95% данных в системе спокойно выдерживают eventual consistency,
а strong consistency нужна только на узком, но очень важном “ядре”.

И это ровно та развилка, которую любят поднимать на собесах:

> “Где в вашей системе вам действительно нужна strong consistency, а где вы сознательно согласитесь на eventual?”

Хороший ответ — это не “я хочу всё strong”, а набор конкретных сценариев:

* денежный ledger, жёсткие инварианты по остаткам, критичные ACL — strong;
* поиск, каталоги, кеши, аналитика, рекомендательные блоки — eventual с понятными компенсирующими механизмами.

---

## 8. Как жить со strong consistency, если деваться некуда

Разумный подход: **локализовать** strong consistency там, где она действительно нужна,
и аккуратно интегрировать её в более “мягкий” мир вокруг.

Некоторые приёмы:

### 8.1. Кворумы и “достаточно хорошая” консистентность

Вместо “всем, всегда и синхронно”:

* пишем в большинство узлов;
* читаем из большинства;
* при этом конфигурация подобрана так, что пересечение множеств чтения и записи гарантировано.

Это даёт strong consistency для конкретного объекта,
не убивая систему полностью.

### 8.2. Strong для автора, eventual для всех остальных

Паттерн “read-your-writes для того, кто написал”:

* пользователь, который только что сделал write,
  читает свой state из сильноконсистентного пути (лидер, master, локальный стор);
* все остальные клиенты (другие пользователи, анонимы) читают из eventual-консистентных индексов/реплик.

Так делают многие крупные системы: автор всегда видит своё новое сообщение,
а остальные — с небольшим лагом.

### 8.3. Ограничение области strong consistency

Вместо “вся система должна быть strong consistent”:

* выделяем небольшой “core”:

    * баланс,
    * заказы,
    * критичные ACL и т.п.;
* вокруг него строим “мир eventual consistency”:

    * поисковые индексы,
    * кеши,
    * аналитика,
    * уведомления.

Strong consistency становится локальным инвариантом отдельных сервисов/таблиц,
а не свойством всего кластера.

### 8.4. Write-through / write-around кеши

Если данные критичны:

* пишем сначала в хранилище истины, затем обновляем кеш (write-through);
* либо не читаем из кеша прямо после записи (write-around + read-after-write из базы).

Задача — не допустить ситуации, когда кеш длительно “отстаёт” от источника истины по важным данным.

### 8.5. Пиннинг запросов к одному узлу

Для read-after-write гарантии:

* после записи временно пинним пользователя к конкретной ноде/реплике;
* или используем маркеры “я видел версию не ниже X” и не обслуживаем запрос, пока реплика не догнала.

Это дешевле, чем пытаться сделать весь кластер строго консистентным.

### 8.6. Идемпотентность даже в сильноконсистентных частях

Strong consistency не отменяет:

* повторные запросы;
* дубликаты сообщений;
* рестарты клиентских библиотек.

Любые записывающие операции всё равно должны быть идемпотентными:
одна и та же операция, выполненная дважды, не должна ломать инварианты.

---

## Финал

Strong consistency — это не “галочка в конфиге базы”, а тяжёлый архитектурный выбор.

Она даёт:

* глобально согласованное состояние;
* отсутствие целого класса жёстких аномалий;
* уверенность в критичных инвариантах.

И одновременно:

* увеличивает latency и tail;
* ухудшает availability;
* усложняет инфраструктуру;
* душит масштабирование записи.

Поэтому взрослая система устроена так:

* есть небольшой, тщательно продуманный “strong core” — то, за что реально больно;
* вокруг него — слои кешей, индексов и сервисов, живущих на eventual consistency;
* явные протоколы интеграции между этими мирами: события, outbox, CDC, саги.

И главный фильтр при обсуждении strong consistency должен быть не “красиво ли это”,
а “ошибка здесь действительно настолько дорога, чтобы платить за неё всей этой сложностью”.
