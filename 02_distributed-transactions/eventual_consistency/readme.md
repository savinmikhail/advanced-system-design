## Блок 3.12. Eventual Consistency в распределённых системах

## 1. Мост от распределённых транзакций

В блоке про распределённые транзакции мы уже увидели, что саги и outbox неизбежно приводят нас к **eventual consistency**:
деньги, товар, заказ и уведомления перестают жить в одной большой транзакции
и разъезжаются по времени между сервисами и хранилищами.

Мы сознательно согласились на модель:
**“прямо сейчас разные сервисы могут видеть разные срезы мира, но со временем всё сойдётся”**.

Сейчас не будем заново рисовать схему “заказ → биллинг → инвентарь → уведомления” —
будем ссылаться на уже знакомый пример с оформлением заказа в маркетплейсе.
Главный вопрос этой части другой:

* что именно означает такая модель для пользователя;
* как она выглядит в метриках и UX;
* какие архитектурные решения помогают жить с ней безопасно.

Отсюда и рождаются ситуации вида: заказ уже есть в `orders`, но в поиске и аналитике он появится только через секунды–минуты — и пользователю кажется, что система “глючит”.

---

## 2. Что такое eventual consistency по-человечески

Начнём с определения без академического мусора.

**Eventual consistency** — это модель, в которой система говорит примерно следующее:

> “Прямо сейчас данные могут не быть согласованными во всех репликах и сервисах.
> Но если никто больше не будет писать,
> то через какое-то время все придут к одному и тому же состоянию.”

Ключевые моменты:

* “не сразу” — значит ответы могут быть **разными** в разных местах;
* “если никто больше не пишет” — речь о **стабильном хвосте**, а не о перегрузе изменениями;
* “через какое-то время” — нет жёсткой гарантии “200 мс ровно”.

Важно: eventual consistency — это не хаос “как повезёт”.
Это **осознанно более слабая модель**, которую выбирают ради:

* доступности (система не ложится при сетевых проблемах),
* масштабируемости (можно спокойно шардинг/репликацию),
* скорости (не надо блокировать весь мир ради каждого коммита).

---

## 3. Почему сильная консистентность в распределённой системе ломается

Если вы пытаетесь играть в “глобальный ACID поверх зоопарка сервисов”,
вы воюете не с фреймворком, а с физикой.

Три неприятные опоры реальности.

### 3.1. Сеть врёт и иногда молчит

* Пакеты теряются.
* Ответы приходят с непредсказуемой задержкой.
* Нельзя отличить “узел умер” от “пакет не дошёл / ответ опоздал”.

Любой протокол, который требует **синхронного подтверждения от всех**,
становится либо блокирующим, либо дырявым.

### 3.2. Блокировки по всему миру не работают

Глобальные локи теоретически можно придумать. Практически:

* один зависший участник — и всё стоит;
* latency одной “дальней” реплики портит всем жизнь;
* при шардировании и репликации количество взаимодействий растёт нелинейно.

Поэтому “повесим глобальный transaction manager на все базы” —
это не про продовую систему, а про лабораторную.

### 3.3. CAP теорема: если хочешь жить при сетевых проблемах — платишь консистентностью

Очень упрощённо:

* C — consistency (все видят одно и то же “прямо сейчас”);
* A — availability (система отвечает запросам);
* P — partition tolerance (мы не падаем от сетевых разделений).

В распределённой системе **P приходится принимать как данность** — сети неидеальны.
Остаётся выбирать между:

* CP — жёсткая консистентность, но при разделении сети часть запросов будет тупо отклоняться;
* AP — система продолжает отвечать, но в разных местах можно увидеть разные состояния.

Если приземлить это на реальный кейс:

* у вас два региона — Европа и США;
* между ними есть репликация данных и платёжная логика;
* иногда линк между регионами “рвётся” или даёт большие задержки.

Если вы хотите **продолжать принимать заказы и платежи** при разрыве между регионами,
вам приходится выбирать сторону AP:

* каждый регион продолжает принимать операции локально;
* согласованность между регионами станет **eventual** — они догонят друг друга позже через репликацию/события.

Если же вы хотите идеальную консистентность балансов между регионами **в каждый момент времени**,
придётся либо останавливать операции при проблемах с сетью (CP),
либо не расползаться по регионам вообще.

Большинство реальных систем, в особенности микросервисов, баз данных с репликацией, очередей и кешей,
живут ближе к AP и работают с eventual consistency.

---

## 4. Где eventual consistency уже живёт, даже если вы “не подписывались”

Это не экзотика, это повсюду.

Примеры:

* **Kafka / очереди.**
  Consumer отстаёт — значит, аналитика, нотификации и всё, что потребляет события, видят мир с лагом.
* **ElasticSearch / OpenSearch.**
  Документ записали в Postgres, отправили в индекс асинхронно — поиск отстаёт.
* **Репликация в Postgres.**
  Асинхронная реплика отстаёт по WAL — чтения с реплики видят старые данные.
* **CDN.**
  Статика/JSON-кеш на edge-узлах живёт с TTL, которое может быть больше, чем хочется бизнесу.
* **Outbox + CDC.**
  Событие попало в outbox, но ещё не доехало до брокера — другие сервисы “не в курсе”.
* **Саги.**
  Деньги списаны, товар ещё не зарезервирован, заказ в промежуточном состоянии.

Проект может честно думать, что он “строгий и консистентный”,
при этом половина жизненно важных данных уже ездит по таким схемам.

---

## 5. Какие реальные проблемы из этого вылезают

Не абстрактные “анномалии”, а живые симптомы.

### 5.1. Окно рассогласованности

Пользователь обновил данные, а UI продолжает какое-то время показывать старое.

* Обновил профиль — аватарка изменилась в одном месте, но не в другом.
* Создал заказ — в списке заказов его пока нет, хотя “успешно создан”.

### 5.2. Read-your-writes нарушается

Классическая боль:

> “Я только что создал это, почему запрос ‘получи мои данные’ говорит, что их нет?”

Причина простая: пишем в одну ноду / базу, читаем — с реплики, кеша, поиска и т.п.,
которые ещё не успели обновиться.

### 5.3. Потерянные обновления

Два сервиса/пользователя одновременно меняют одну сущность:

1. первый читает старое значение и обновляет;
2. второй, немного позже, тоже читает старое и обновляет “своё”.

В итоге изменения первого просто затерлись вторым.

### 5.4. Дубликаты событий

Большинство нормальных очередей и брокеров — **at-least-once**.

* потребитель упал после обработки, но до ack — сообщение придёт ещё раз;
* “гарантированная доставка” почти всегда значит “готовься к дубликатам”.

Если операции не идемпотентны — всё, приехали.

### 5.5. Гонки между сервисами

Сага:

1. сервис `orders` создаёт заказ;
2. сервис `notifications` уже отправил письмо “Заказ создан”;
3. сервис `billing` фейлится, заказ откатывается/отменяется.

Пользователь получил письмо о заказе, которого формально уже нет.

### 5.6. Кэш врёт

* Redis / CDN / in-process кеш содержат старые данные;
* кто-то почистил только одну из ступеней;
* TTL подобрано “примерно на глаз”.

Пользователь делает действие → система отвечает данными “из прошлого”.

---

## 6. Как уменьшать боль: локальные приёмы

С eventual consistency “до нуля” не уйти, но можно радикально смягчить углы.

### 6.1. Read-after-write из локального хранилища

Простейший, но очень важный приём:

> После записи показываем пользователю данные,
> **прочитанные с того же пути, куда писали**,
> а не через отстающие индексы/кеши.

Например:

* заказ записали в Postgres;
* ElasticSearch ещё не успел индексировать;
* при редиректе на “детали заказа” читаем **из Postgres**, а не из поиска.

То же с профилем, балансом и т.п.:

* обновили профиль — отдаем ответ и UI сразу использует payload ответа,
  а не “ждёт пока синхронизация долетит до всех”.

### 6.2. Sticky sessions / пиннинг на реплику

Если есть master + реплики:

* для пользователя, который только что писал,
  временно пинним чтения на master;
* либо держим информацию о “последнем LSN”, до которого реплика должна догнать.

В простом варианте — просто не читаем критические данные с реплики сразу после записи.

### 6.3. Версионирование и optimistic locking

Чтобы не ловить потерянные обновления:

* каждая запись имеет `version` / `updated_at`;
* `UPDATE` делаем с условием `WHERE id = :id AND version = :oldVersion`;
* если строк 0 — значит, кто-то обновил раньше → надо перечитать и решить, что делать.

Это не решает eventual consistency между сервисами,
но защищает хотя бы от тихих затираний.

### 6.4. Outbox + CDC как базовый слой

Всё, что касается синхронизации между сервисами, должно идти через:

* локальную транзакцию (данные + запись в outbox),
* CDC / Debezium-стрим, который гарантированно отправляет событие.

Без этого рассуждать о “согласованности” вообще бессмысленно — события будут теряться/дублироваться без контроля.

### 6.5. Идемпотентность везде, где есть сеть

* любой вызываемый извне action имеет `operation_id` / ключ идемпотентности;
* повторный вызов с тем же ID не должен ломать состояние:

   * либо ничего не делает,
   * либо возвращает прежний результат.

Это единственный нормальный способ жить с ретраями, дубликатами, reorder’ом.

### 6.6. Retries с backoff, а не “пуляем пока не повезёт”

Ретраи нужны, иначе временные сбои превращаются в перманентную ошибку.

Но:

* ретраи без backoff → retry storm;
* во временные окна деградации вы забиваете и так мучающуюся систему.

Поэтому:

* экспоненциальный backoff;
* лимиты на количество попыток;
* circuit breaker, чтобы не долбиться в заведомо мёртвую зависимость.

### 6.7. Временные эвристики

В реальной жизни часто работают такие вещи:

* “после успешной операции мы ожидаем, что данные устаканятся за X миллисекунд/секунд”;
* UI может:

   * временно показывать локальное состояние,
   * отображать статус “синхронизация в процессе”,
   * через время “освежить” данные.

Это уже UX-слой, но он сильно влияет на то, как пользователи воспринимают eventual consistency.

---

## 7. Архитектурные паттерны, которые помогают

Это уже не локальные штуки, а **уровень архитектуры**.

### 7.1. Outbox pattern

Фактически базовый кирпич:

* любые доменные события появляются в outbox в одной транзакции с записью в таблицу;
* CDC/коннектор читает outbox и отправляет события в Kafka/очередь/другие системы;
* потребители строят своё состояние (кеши, проекции, индексы) уже из этого потока.

Такое разделение:

* “истина” — в локальной БД;
* “раздача” — через стрим.

Без outbox’а eventual consistency превращается в игру “угадал не угадал”.

### 7.2. Data reconciliation

Никакая система не будет идеальной, поэтому нужны:

* периодические джобы, которые сравнивают состояние нескольких источников:

   * заказы в `orders` vs. заказы в `billing`;
   * данные в Postgres vs. данные в Elastic;
* отчёты/алерты о расхождениях;
* автоматические/ручные “чинящие” скрипты.

Это не очень красиво, но это реальная взрослая практика.

### 7.3. Materialized views и проекции

Часто чтение идёт не из основной таблицы, а из отдельной “проекции”:

* таблица/индекс, специально подготовленный под конкретные запросы;
* строится асинхронно из стрима событий;
* может быть в той же базе, может — в другой (например, Postgres → ClickHouse для аналитики).

Это как “отдельная реляционная модель для чтения”, которая живёт по своим правилам.

### 7.4. Event Sourcing

Более радикальный подход:

* источник истины — **журнал событий**;
* состояние — это результат применения всех событий;
* любые “проекции” (таблицы для чтения, индексы, кэши) — материализованные представления этого журнала.

По сути, eventual consistency становится не багом, а основным режимом работы:
проекции всегда догоняют историю с каким-то лагом.

Подходит не всем, но для сложных доменов (финтех, игры, сложные бизнес-процессы) — очень полезный подход.

### 7.5. CQRS (разделение чтения и записи)

Идея:

* путь записи — один (оптимизирован под доменную модель и инварианты);
* путь чтения — другой (оптимизирован под запросы, фильтры, списки).

Консистентность между ними становится архитектурным вопросом:

* запись → событие → обновление read-модели;
* чтения живут с осознанием, что они смотрят на “срез, который немного отстаёт”.

---

## 8. Психологический момент

Самое важное — честно проговорить себе и команде:

> **Eventual consistency — это не баг. Это осознанный выбор архитектуры.**

Каждый раз, когда вы:

* вводите асинхронную репликацию;
* ставите очереди;
* используете кеши с TTL;
* шардите данные по разным базам;

— вы выбираете **меньше блокировок и выше доступность**
в обмен на **риск временной рассогласованности**.

Любой “странный” кейс — это не “система сошла с ума”,
это следствие одного из этих выборов.

---

## 9. Когда eventual consistency недопустима

Есть области, где “подождёт, пока устаканится” — не вариант.

Примеры:

* **Жёсткие финансовые транзакции**, где:

   * отчётность должна сходиться до копейки,
   * регуляторы не интересуются вашими очередями и CDC.
* **Юридически значимые операции**:

   * подписание договоров;
   * фиксация прав доступа/владения.
* **Security / ACL**:

   * если права доступа обновились,
     “пока не дойдёт” — это окно для эскалации.
* **High-frequency trading и подобные штуки**,
  где любая задержка/несогласованность — прямые деньги.
* Всё, где **нет адекватной компенсации**:

   * нельзя “переиграть” сделку задним числом;
   * нельзя “откатываться событиями”.

В таких местах либо:

* отказываются от микросервисной/распределённой архитектуры и живут на более жёсткой модели (одна база, строгие транзакции),
* либо вокруг этого куска строят всё остальное, но его держат максимально локализованным и “консервативным”.

---

Итог: eventual consistency — это цена за масштабируемость и доступность.

Нормальная взрослая система:

* **не притворяется**, что у неё везде ACID;
* явно отмечает зоны eventual consistency;
* даёт пользователю понятный UX поверх этой реальности;
* и имеет инструменты, чтобы находить и чинить рассинхроны, когда они всё-таки прорываются наружу.
