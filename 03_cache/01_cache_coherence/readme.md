## B. Cache Coherence в распределённых системах

### B1. Проблема расхождения слоёв

Теперь предположим такую ситуацию

08:00:00 — Пользователь Иван заходит в "Мой профиль", меняет адрес доставки:
```text
Было: "Москва, ул. Ленина, 10"
Стало: "Санкт-Петербург, Невский пр., 25"
```

08:00:02 — Адрес успешно обновился, Иван видит сообщение: ✅ "Адрес сохранён"

08:00:10 — Иван переходит в корзину, чтобы оформить заказ
08:00:11 — В корзине показывается старый адрес: "Москва, ул. Ленина, 10" ❌

Иван пишет в техподдержку
```text
Все фигня ничего не работает верните деньги!
```

Что произошло под капотом?

![Слои кэша: профиль vs корзина](/03_cache/assets/02-cache-coherence-profile-cart.png)

То есть информация об адресе пользователя хранилась в нескольких слоях (и инстансах)

| Слой | Ключ | Значение | Статус |
|------|------|----------|--------|
| **БД** | `users.address` | СПб, Невский 25 | ✅ Обновлён |
| **Redis** | `profile:user:123` | СПб, Невский 25 | ✅ Инвалидирован, перезагружен |
| **Redis** | `cart:user:123` | Москва, Ленина 10 | ❌ **НЕ инвалидирован!** |
| **L1 APCu** | `profile:user:123` (server 1) | СПб, Невский 25 | ✅ Инвалидирован |
| **L1 APCu** | `cart:user:123` (server 2) | Москва, Ленина 10 | ❌ **НЕ инвалидирован!** |

Получилось так, что при обновлении мы инвалидировали только часть слоев

Вдобавок к тому что разные экраны показывают разные данные, так еще и экран пользователя может показывать то одно значение то другое в зависимости от того на какой инстанс его кинет

Здесь мы приходим к понятию Cache Coherence
Cache Coherence — это свойство системы, при котором все копии одного и того же объекта данных в разных кэшах остаются согласованными.

Вопросы для размышления

Q1: Как быстро мы требуем согласованность?

* Мгновенно (strong coherence)? — дорого
* В течение секунды (eventual coherence)? — реалистично
* В течение минуты? — зависит от бизнеса

Q2: Какие данные критичны к coherence?

* Адрес доставки: средняя критичность (eventual до 5 секунд окей)
* Баланс счёта: высокая критичность (<1 секунды)
* Лента новостей: низкая критичность (до 5 минут окей)

Q3: Как проверить, что coherence нарушена?

* Метрика stale_read_rate (об этом расскажу в разделе D)


### B2. Стратегии наполнения кэша

Так как мы можем бороться с расхождением кеша? Сначала надо определиться кто в системе будет отвечать за это

Есть два разных подхода:

| Подход | Кто управляет | Плюсы | Минусы |
|--------|---------------|-------|--------|
| **Сервис-driven** | Код сервиса явно работает с кэшем | Полный контроль | Легко ошибиться |
| **Cache-driven** | Кэш-слой прозрачно работает с БД | Меньше кода | Меньше гибкости |

В свою очередь из этих подходов рождаются 4 разных стратегии наполнения кеша

#### Стратегия 1: Cache-Aside (Lazy Loading)
Он Самый простой

При этом подходе всем управляет сервис. То есть наш код явно

1. Проверяет кэш
2. Если нет — ходит в БД
3. Кладёт в кэш
4. Сам же делает invalidate

![Cache-Aside: последовательность вызовов](/03_cache/assets/03-cache-aside-sequence.png)

![Cache-Aside: поток данных](/03_cache/assets/04-cache-aside-flow.png)

пример псевдокода

![Пример кода Cache-Aside](/03_cache/assets/12-cache-aside-php.png)

Все очень прозрачно

Но возникает ряд проблем:
- так как вероятно мы дублируем это поведение в разных местах бизнес логики, то мы можем забыть где-то инвалидировать какой-то из связанных ключей, как это было в примере выше про адрес пользователя

  ![Ошибка инвалидации связанных ключей](/03_cache/assets/13-cache-aside-bug-example-php.png)
- либо мы можем забыть инвалидировать какой-то из слоев
- вдобавок можем столкнуться с race condition: Запрос A обновил БД, удалил ключ, запрос B успел прочитать старые данные и записал их обратно в кэш. подробнее об этом поговорим позже

Cache-aside работает, пока у тебя 2 экрана, потом становится все сложнее этим управлять, так как размазано по коду

Из плюсов:
✅ Полный контроль над логикой
✅ Простая реализация

#### Стратегия 2: Read-Through Cache

В какой-то момент становится более поддерживаемым решением двинуть эту логику в редис
То есть для нашего сервиса все становится проще и прозрачнее: мы обращаемся к кешу, если у кеша нет такого ключа то он идет в бд и сам себя обновляет

Получается лучше:
- меньше или вообще нет duplicate логики - Не нужно бегать по всему коду чтоб добавить/убрать инвалидацию
- согласованность между Redis и DB стала стабильнее
- исчезает часть race conditions - Нет шансов записать в кэш устаревшие данные руками

![Read-Through: последовательность вызовов](/03_cache/assets/05-read-through-sequence.png)

![Read-Through: поток данных](/03_cache/assets/06-read-through-flow.png)

Это не магическая возможность редиса а скорее паттерн в коде обертке над кешом:

![Пример кода Read-Through](/03_cache/assets/14-read-through-php.png)

Но взамен мы получаем новые проблемы:
Кеш не знает когда запись в базе обновляется, он обновляется только при чтении при cache-miss
То есть пользователь, который только что обновил адрес, увидит старый значение до следующего cache miss.

То есть мы закрыли часть проблем, но получили новые

#### 3. Write-Through Cache

Эту проблему можно исправить используя стратегию  Write-Through

Как работает:

1. Запись идёт в кэш
2. Кэш синхронно пишет в БД
3. Только после этого запрос считается успешным

![Write-Through: последовательность вызовов](/03_cache/assets/07-write-through-sequence.png)

![Write-Through: поток данных](/03_cache/assets/08-write-through-flow.png)

пример кода

![Пример кода Write-Through](/03_cache/assets/15-write-through-php.png)

Теперь Рабочие данные **всегда** согласованы с бд (источником истины)

Из минусов - кеш становится точкой отказа. Если редис упадет, то мы не сможем писать в базу
И если база тормозит, то редису приходится ждать

Следующая проблема - Высокая латентность на write
Раньше мы писали только в бд, теперь сначала в кеш, и только потом в бд

В write-heavy системах (балансы, корзины) это прям дорого.

Таким образом согласованнасть у нас почти идеальная, но стоимость такого решения высокая

#### 4. Write-Behind (Write-Back Cache)

Для решения этой проблемы можем перейти к Write-Behind стратегии

Как работает:

1. Запись делается только в кэш
2. Кэш кладёт операцию в очередь
3. БД обновляется фоном (через батчи)

![Write-Behind: последовательность вызовов](/03_cache/assets/09-write-behind-sequence.png)

![Write-Behind: поток данных](/03_cache/assets/10-write-behind-flow.png)

Пример кода

![Пример кода Write-Behind](/03_cache/assets/16-write-behind-php.png)

Таким образом запись у нас снова становится быстрой, бд можно наполнять батчами, что дешево к ресурсам

Из минусов -
- То есть write-behind — это сознательный уход от сильной консистентности  в пользу latency & throughput, так как инструменты сохранения consistency из ACID у нас исчезают. пользователь видит что все ок, хотя в базу никогда не ляжет запись
  то есть можем использовать либо в event sourcing/eventual consistency вроде saga, либо для данных которые допустимо терять: аналитика, логи и тп
- происходит неконсистентность в обратную сторону - в кеше данные свежее чем в базе. Но это менее страшно для пользователя, так как данные он получает из кеша
- Так же возникает риск потерять данные, если упадет очередь, что в целом решаемо через durable queue или  Kafka.

Итого:

| Стратегия         | Где используется      | Что решает                     | Что ломает             | Coherence  |
| ----------------- | --------------------- | ------------------------------ | ---------------------- | ---------- |
| **Cache-Aside**   | стартапы, быстрые MVP | простота                       | stale data everywhere  | ❌ слабая   |
| **Read-Through**  | средние проекты       | уменьшает ошибки разработчиков | invalidate тяжёлый     | ◒ средняя  |
| **Write-Through** | финансы, лимиты       | сильная согласованность чтения | write дорого           | ✔ высокая  |
| **Write-Behind**  | high-load, аналитика  | дешёвые записи, батчи          | сложность, риск потерь | ◒ eventual |


### B3. Инвалидация

Мы разобрали как писать в кеш с нужным уровнем когерентности

А как удалять данные из кеша?

Есть даже известная фраза Фила Карлтона сказанная 28 лет назад
“В программировании есть только две сложные проблемы: инвалидация кеша и придумывание названий”

Здесь нам доступны три основных подхода.

#### 1) TTL-only: “пусть всё само протухает”

Самый простой, но самый неэффективный
При этом подходе мы вообще не инвалидируем кэш явно, а просто ждем пока его срок жизни истечет. Зато нам не нужно писать лишний код или придумывать какую-то архитектуру

Из минусов:
1. stale data гарантирована
2. время невалидности = время TTL - если TTL 5 минут, то 5 минут у вас всё рассинхронизировано
3. никаких гарантий когерентности между разными слоями (L1, Redis, CDN, браузер)

Этот подход окей для ленты новостей, популярных товаров, каталога.
Но ужасен для адресов доставки, балансов, лимитов.

#### 2) Event-based invalidation (Pub/Sub)

Для борьбы со stale data мы переходим к Event-based invalidation

Здесь сразу после изменения данных мы отправляем событие, например user.updated

И все подписчики решают, что делать:
* удалить ключ
* обновить кэш
* сбросить локальный L1
* отправить обновление в CDN
* инвалидировать связанные ключи

Таким образом у нас возрастает cache coherence - одно событие инвалидирует все слои (L1, Redis, CDN)
stale-read окно уменьшается с минут до миллисекунд

#### Tag-based invalidation

Вот мы сказали что подписчики умеют инвалидирвоать связанные ключи
Но как это работает?
Для решения такой задачи есть возможность помечать разные ключи одинаковыми тегами, если такая возможность есть в вашем фреймворке

![Tag-based invalidation: пример тегов](/03_cache/assets/17-tag-based-invalidation-text.png)

В контексте coherence это критично, потому что:
* все слои обновляются атомарно
* нет риска забыть один ключ
